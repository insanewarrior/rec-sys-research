{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from scipy.sparse import csr_matrix\n",
    "from weighting_strategies import (\n",
    "    bm25_weight, tfidf_weight, normalized_weight,\n",
    "    log_weight, log_idf_weight, power_weight,\n",
    "    pmi_weight, robust_user_centric_weight, sigmoid_propensity_weight, power_lift_weight, robust_user_centric_weight_v2\n",
    ")\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.evaluation import train_test_split, ranking_metrics_at_k\n",
    "\n",
    "import cornac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d18967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path to resolve imports from sibling directories\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.sparse import transform_dataframe_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7200551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
      "will be cached into /home/coder/.cornac/ml-20m/ratings.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76af714be8f459392a4b15aeb39ab33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping ...\n",
      "File cached!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(138493, 26744, 20000263)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_df = (\n",
    "    pd.DataFrame(\n",
    "        data=cornac.datasets.movielens.load_feedback(variant=\"20M\"),\n",
    "        columns=['user_id', 'item_id', 'target']\n",
    "    )\n",
    "    .loc[:, ['user_id', 'item_id', 'target']]\n",
    "    .dropna()\n",
    ")\n",
    "movielens_df['user_id'].nunique(), movielens_df['item_id'].nunique(), movielens_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d63988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (138493, 26744), Val Shape: (138493, 26744), Test Shape: (138493, 26744)\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix, user_mapping, item_mapping = transform_dataframe_to_sparse(\n",
    "    movielens_df, row_field='user_id', col_field='item_id', data_field='target'\n",
    ")\n",
    "\n",
    "\n",
    "train_val_mat, test_mat = train_test_split(user_item_matrix, train_percentage=0.9, random_state=42)\n",
    "train_mat, val_mat = train_test_split(train_val_mat, train_percentage=0.9, random_state=42)\n",
    "\n",
    "print(f\"Train Shape: {train_mat.shape}, Val Shape: {val_mat.shape}, Test Shape: {test_mat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/movielens_20m_lmf\"\n",
    "results_filename = \"movielens_20m_lmf_results.csv\"\n",
    "\n",
    "import time\n",
    "\n",
    "def run_hyperparameter_optimization(\n",
    "    train_mat: csr_matrix,\n",
    "    val_mat: csr_matrix,\n",
    "    train_val_mat: csr_matrix,\n",
    "    test_mat: csr_matrix,\n",
    "    weighting_strategy: str,\n",
    "    algorithm: str,\n",
    "    n_trials: int = 20,\n",
    "    output_dir: str = None,\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "    algorithms = {\n",
    "        \"LMF_factors=100\": lambda: LogisticMatrixFactorization(\n",
    "            factors=100,\n",
    "            learning_rate=1,\n",
    "            regularization=0.6,\n",
    "            iterations=30,\n",
    "            random_state=42\n",
    "        ),\n",
    "    }\n",
    "    strategies = [\n",
    "        \"no_weighting\",\n",
    "        \"bm25\",\n",
    "        \"tfidf\",\n",
    "        \"log\", \n",
    "        \"log_idf\n",
    "        \"power\",\n",
    "        \"normalized\",\n",
    "        \"pmi\",\n",
    "        \"robust_user_centric\",\n",
    "        \"robust_user_centric_weight_v2\",\n",
    "        \"sigmoid_propensity\",\n",
    "        \"power_lift\"\n",
    "    ]\n",
    "    if weighting_strategy not in strategies:\n",
    "        raise ValueError(f\"Weighting strategy '{weighting_strategy}' is not recognized.\")\n",
    "    strategy = weighting_strategy\n",
    "\n",
    "    if algorithm not in algorithms:\n",
    "        raise ValueError(f\"Algorithm '{algorithm}' is not recognized.\")\n",
    "    algo_name = algorithm\n",
    "    AlgoFactory = algorithms[algorithm]\n",
    "\n",
    "    print(f\"Running optimization for {algo_name} with {strategy}...\")\n",
    "\n",
    "    def get_weighted_matrix(matrix, params):\n",
    "        weighted = matrix.copy()\n",
    "        if strategy == \"bm25\":\n",
    "            weighted = bm25_weight(weighted, K1=params.get(\"bm25_k1\"), B=params.get(\"bm25_b\"))\n",
    "        elif strategy == \"log_idf\n",
    "            weighted = log_idf_weight(weighted, alpha=params.get(\"conf_alpha\"))\n",
    "        elif strategy == \"power\":\n",
    "            weighted = power_weight(weighted, p=params.get(\"power_p\"))\n",
    "        elif strategy == \"tfidf\":\n",
    "            weighted = tfidf_weight(weighted)\n",
    "        elif strategy == \"log\":\n",
    "            weighted = log_weight(weighted)\n",
    "        elif strategy == \"normalized\":\n",
    "            weighted = normalized_weight(weighted)\n",
    "        elif strategy == \"pmi\":\n",
    "            weighted = pmi_weight(weighted)\n",
    "        elif strategy == \"robust_user_centric\":\n",
    "            weighted = robust_user_centric_weight(weighted, scale_factor=params.get(\"scale_factor\"))\n",
    "        elif strategy == \"sigmoid_propensity\":\n",
    "            weighted = sigmoid_propensity_weight(weighted, p=params.get(\"p\"), beta=params.get(\"beta\"))\n",
    "        elif strategy == \"power_lift\":\n",
    "            weighted = power_lift_weight(weighted, p=params.get(\"p\"))\n",
    "        elif strategy == \"robust_user_centric_weight_v2\":\n",
    "            weighted = robust_user_centric_weight_v2(weighted, lower_q=params.get(\"lower_q\"), upper_q=params.get(\"upper_q\"))\n",
    "        return weighted\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {}\n",
    "        # Suggest weighting strategy parameters\n",
    "        if strategy == \"bm25\":\n",
    "            params[\"bm25_k1\"] = trial.suggest_float(\"bm25_k1\", 0.1, 1000)\n",
    "            params[\"bm25_b\"] = trial.suggest_float(\"bm25_b\", 0.0, 1.0)\n",
    "        elif strategy == \"log_idf\n",
    "            params[\"conf_alpha\"] = trial.suggest_float(\"conf_alpha\", 1.0, 150.0)\n",
    "        elif strategy == \"power\":\n",
    "            params[\"power_p\"] = trial.suggest_float(\"power_p\", 0.1, 1.5)\n",
    "        elif strategy == \"robust_user_centric\":\n",
    "            params[\"scale_factor\"] = trial.suggest_float(\"scale_factor\", 0.1, 10.0)\n",
    "        elif strategy == \"robust_user_centric_weight_v2\":\n",
    "            params[\"lower_q\"] = trial.suggest_float(\"lower_q\", 5.0, 45.0)\n",
    "            params[\"upper_q\"] = trial.suggest_float(\"upper_q\", 55.0, 95.0)\n",
    "        elif strategy == \"sigmoid_propensity\":\n",
    "            params[\"p\"] = trial.suggest_float(\"p\", 0.1, 5.0)\n",
    "            params[\"beta\"] = trial.suggest_float(\"beta\", 0.0, 1.0)\n",
    "        elif strategy == \"power_lift\":\n",
    "            params[\"p\"] = trial.suggest_float(\"p\", 0.1, 1.5)\n",
    "        weighted_train = get_weighted_matrix(train_mat, params)\n",
    "\n",
    "        # Train Model\n",
    "        model = AlgoFactory()\n",
    "        model.fit(weighted_train, show_progress=False)\n",
    "\n",
    "        # Evaluate on Validation Set\n",
    "        return ranking_metrics_at_k(model, train_mat, val_mat, K=20, show_progress=False)['ndcg']\n",
    "\n",
    "    # Optimize only if strategy has parameters\n",
    "    current_trials = n_trials if strategy in [\"bm25\", \"log_idf\"power\", \"robust_user_centric\", \"robust_user_centric_weight_v2\", \"sigmoid_propensity\", \"power_lift\"] else 1\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=current_trials, n_jobs=-1)\n",
    "\n",
    "    # --- Final Retraining & Testing ---\n",
    "    # Use best params to weight the full train_val matrix\n",
    "    best_params = study.best_params\n",
    "    weighted_train_val = get_weighted_matrix(train_val_mat, best_params)\n",
    "\n",
    "    # Train Final Model\n",
    "    final_model = AlgoFactory()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    final_model.fit(weighted_train_val, show_progress=False)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate on Test Set\n",
    "    metrics_at_10 = ranking_metrics_at_k(final_model, train_val_mat, test_mat, K=10, show_progress=False)\n",
    "    metrics_at_20 = ranking_metrics_at_k(final_model, train_val_mat, test_mat, K=20, show_progress=False)\n",
    "\n",
    "    results.append({\n",
    "        \"Algorithm\": algo_name,\n",
    "        \"Strategy\": strategy,\n",
    "        \"Number of Optimization Trials\": current_trials,\n",
    "        \"Best Val NDCG@20\": study.best_value,\n",
    "        \"Test NDCG@10\": metrics_at_10['ndcg'],\n",
    "        \"Test NDCG@20\": metrics_at_20['ndcg'],\n",
    "        \"Test Precision@10\": metrics_at_10['precision'],\n",
    "        \"Test Precision@20\": metrics_at_20['precision'],\n",
    "        \"Final Train Time (s)\": end_time - start_time,\n",
    "        \"Best Params\": best_params\n",
    "    })\n",
    "\n",
    "    if output_dir:\n",
    "        output_path = os.path.join(output_dir, f\"{algo_name}_{strategy}_results.csv\")\n",
    "        pd.DataFrame(results).to_csv(output_path, index=False)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a01f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ffa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:49:58,653] A new study created in memory with name: no-name-fdccf3ce-5e75-4c2c-b366-28b02c2b648f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with no_weighting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:52:04,852] Trial 0 finished with value: 0.03623736047903792 and parameters: {}. Best is trial 0 with value: 0.03623736047903792.\n"
     ]
    }
   ],
   "source": [
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"no_weighting\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:23,356] A new study created in memory with name: no-name-66bec88d-ce95-4373-9952-9519ac199340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with bm25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:28,270] Trial 4 finished with value: 0.11093201450111392 and parameters: {'bm25_k1': 449.5435146186711, 'bm25_b': 0.9673521867428252}. Best is trial 4 with value: 0.11093201450111392.\n",
      "[I 2026-02-08 11:47:28,431] Trial 7 finished with value: 0.11331301948421049 and parameters: {'bm25_k1': 252.49082695516736, 'bm25_b': 0.9140693061206121}. Best is trial 7 with value: 0.11331301948421049.\n",
      "[I 2026-02-08 11:47:28,441] Trial 6 finished with value: 0.11399842397323168 and parameters: {'bm25_k1': 225.27138083941168, 'bm25_b': 0.799687653452424}. Best is trial 6 with value: 0.11399842397323168.\n",
      "[I 2026-02-08 11:47:28,462] Trial 1 finished with value: 0.11862926360337808 and parameters: {'bm25_k1': 347.3224725671412, 'bm25_b': 0.7496673602128733}. Best is trial 1 with value: 0.11862926360337808.\n",
      "[I 2026-02-08 11:47:28,494] Trial 2 finished with value: 0.12426670191812765 and parameters: {'bm25_k1': 890.9368293378736, 'bm25_b': 0.062470166850947195}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:28,516] Trial 0 finished with value: 0.12343497342209785 and parameters: {'bm25_k1': 600.3116502224156, 'bm25_b': 0.090521487928241}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:28,522] Trial 3 finished with value: 0.1151144738423877 and parameters: {'bm25_k1': 527.0117608762796, 'bm25_b': 0.27688522932508386}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:28,535] Trial 5 finished with value: 0.11809244002299514 and parameters: {'bm25_k1': 959.1906065977146, 'bm25_b': 0.7941528353843473}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,496] Trial 13 finished with value: 0.11896191439093413 and parameters: {'bm25_k1': 504.2997729710222, 'bm25_b': 0.2222647248665257}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,670] Trial 8 finished with value: 0.11373583332712935 and parameters: {'bm25_k1': 903.1121506798656, 'bm25_b': 0.8992452839854153}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,683] Trial 15 finished with value: 0.11365307954927373 and parameters: {'bm25_k1': 174.97841446061295, 'bm25_b': 0.9717488062277841}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,690] Trial 9 finished with value: 0.12127082502781959 and parameters: {'bm25_k1': 415.1764472004971, 'bm25_b': 0.46800640032599183}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,738] Trial 11 finished with value: 0.11215920652986594 and parameters: {'bm25_k1': 792.364613036399, 'bm25_b': 0.3696604772842852}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,744] Trial 14 finished with value: 0.11900962621346929 and parameters: {'bm25_k1': 65.76546563223658, 'bm25_b': 0.0882606258369596}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,764] Trial 12 finished with value: 0.11839546360584437 and parameters: {'bm25_k1': 718.3239356999102, 'bm25_b': 0.20164739135585785}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:33,769] Trial 10 finished with value: 0.11615240231655649 and parameters: {'bm25_k1': 544.8247116720862, 'bm25_b': 0.8664132051055438}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:36,302] Trial 16 finished with value: 0.11834449342940156 and parameters: {'bm25_k1': 91.76285207253399, 'bm25_b': 0.7360401832277593}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:36,329] Trial 19 finished with value: 0.12293878363236811 and parameters: {'bm25_k1': 729.6495848723098, 'bm25_b': 0.017846121290426092}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:36,364] Trial 17 finished with value: 0.12199633157371652 and parameters: {'bm25_k1': 755.0989005700886, 'bm25_b': 0.02794116271567631}. Best is trial 2 with value: 0.12426670191812765.\n",
      "[I 2026-02-08 11:47:36,365] Trial 18 finished with value: 0.12152172426536985 and parameters: {'bm25_k1': 725.8098329963017, 'bm25_b': 0.009397035145939259}. Best is trial 2 with value: 0.12426670191812765.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>bm25</td>\n",
       "      <td>20</td>\n",
       "      <td>0.124267</td>\n",
       "      <td>0.122301</td>\n",
       "      <td>0.146816</td>\n",
       "      <td>0.13838</td>\n",
       "      <td>0.17847</td>\n",
       "      <td>0.606669</td>\n",
       "      <td>{'bm25_k1': 890.9368293378736, 'bm25_b': 0.062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm Strategy  Number of Optimization Trials  Best Val NDCG@20  \\\n",
       "0  LMF_factors=100     bm25                             20          0.124267   \n",
       "\n",
       "   Test NDCG@10  Test NDCG@20  Test Precision@10  Test Precision@20  \\\n",
       "0      0.122301      0.146816            0.13838            0.17847   \n",
       "\n",
       "   Final Train Time (s)                                        Best Params  \n",
       "0              0.606669  {'bm25_k1': 890.9368293378736, 'bm25_b': 0.062...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"bm25\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:37,753] A new study created in memory with name: no-name-d54e0ccb-cb1e-4ee2-9f30-be538a4783b6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with tfidf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:38,455] Trial 0 finished with value: 0.12357519240498764 and parameters: {}. Best is trial 0 with value: 0.12357519240498764.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123575</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.149315</td>\n",
       "      <td>0.144318</td>\n",
       "      <td>0.180602</td>\n",
       "      <td>0.627758</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm Strategy  Number of Optimization Trials  Best Val NDCG@20  \\\n",
       "0  LMF_factors=100    tfidf                              1          0.123575   \n",
       "\n",
       "   Test NDCG@10  Test NDCG@20  Test Precision@10  Test Precision@20  \\\n",
       "0      0.127691      0.149315           0.144318           0.180602   \n",
       "\n",
       "   Final Train Time (s) Best Params  \n",
       "0              0.627758          {}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"tfidf\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c993f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:39,922] A new study created in memory with name: no-name-585adf99-f04b-44f3-b2db-ca2425d33c57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with log...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:40,658] Trial 0 finished with value: 0.1303761409841096 and parameters: {}. Best is trial 0 with value: 0.1303761409841096.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>log</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130376</td>\n",
       "      <td>0.137035</td>\n",
       "      <td>0.152675</td>\n",
       "      <td>0.150091</td>\n",
       "      <td>0.173614</td>\n",
       "      <td>0.599544</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm Strategy  Number of Optimization Trials  Best Val NDCG@20  \\\n",
       "0  LMF_factors=100      log                              1          0.130376   \n",
       "\n",
       "   Test NDCG@10  Test NDCG@20  Test Precision@10  Test Precision@20  \\\n",
       "0      0.137035      0.152675           0.150091           0.173614   \n",
       "\n",
       "   Final Train Time (s) Best Params  \n",
       "0              0.599544          {}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"log\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7334c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:42,058] A new study created in memory with name: no-name-384feb5d-eb73-4e55-93f3-7c187d187e62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with confidence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:47,066] Trial 7 finished with value: 0.02846572732681722 and parameters: {'conf_alpha': 76.385882746759}. Best is trial 7 with value: 0.02846572732681722.\n",
      "[I 2026-02-08 11:47:47,114] Trial 3 finished with value: 0.030005729328642622 and parameters: {'conf_alpha': 105.95305072498014}. Best is trial 3 with value: 0.030005729328642622.\n",
      "[I 2026-02-08 11:47:47,138] Trial 0 finished with value: 0.07880715451231446 and parameters: {'conf_alpha': 8.240475452849108}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:47,148] Trial 6 finished with value: 0.02976503091219951 and parameters: {'conf_alpha': 122.3952391845651}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:47,150] Trial 2 finished with value: 0.030534501193680872 and parameters: {'conf_alpha': 135.6859830832092}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:47,182] Trial 1 finished with value: 0.03022415108429704 and parameters: {'conf_alpha': 138.54629184466108}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:47,237] Trial 5 finished with value: 0.02945774316515598 and parameters: {'conf_alpha': 128.9903386702416}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:47,264] Trial 4 finished with value: 0.02984891063153617 and parameters: {'conf_alpha': 119.75873336707411}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:52,219] Trial 9 finished with value: 0.030502352010268484 and parameters: {'conf_alpha': 145.0148141615398}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:52,517] Trial 11 finished with value: 0.02889542499546131 and parameters: {'conf_alpha': 42.29484256919008}. Best is trial 0 with value: 0.07880715451231446.\n",
      "[I 2026-02-08 11:47:52,534] Trial 10 finished with value: 0.07986555124689303 and parameters: {'conf_alpha': 8.18993035053296}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:52,576] Trial 8 finished with value: 0.030140141459206602 and parameters: {'conf_alpha': 35.83108153657792}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:52,611] Trial 14 finished with value: 0.039456308957682526 and parameters: {'conf_alpha': 20.936282536104997}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:52,616] Trial 12 finished with value: 0.06502418545385226 and parameters: {'conf_alpha': 11.402571316371104}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:52,664] Trial 15 finished with value: 0.034605104426481535 and parameters: {'conf_alpha': 26.03354206813065}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:52,684] Trial 13 finished with value: 0.027975337637096392 and parameters: {'conf_alpha': 63.78966108894579}. Best is trial 10 with value: 0.07986555124689303.\n",
      "[I 2026-02-08 11:47:55,147] Trial 18 finished with value: 0.09943085389458138 and parameters: {'conf_alpha': 5.773892000005442}. Best is trial 18 with value: 0.09943085389458138.\n",
      "[I 2026-02-08 11:47:55,166] Trial 16 finished with value: 0.030146641905664108 and parameters: {'conf_alpha': 141.05621618171747}. Best is trial 18 with value: 0.09943085389458138.\n",
      "[I 2026-02-08 11:47:55,175] Trial 19 finished with value: 0.10196835028249672 and parameters: {'conf_alpha': 4.667610986492406}. Best is trial 19 with value: 0.10196835028249672.\n",
      "[I 2026-02-08 11:47:55,193] Trial 17 finished with value: 0.11609024650189508 and parameters: {'conf_alpha': 1.3997319432813828}. Best is trial 17 with value: 0.11609024650189508.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>confidence</td>\n",
       "      <td>20</td>\n",
       "      <td>0.11609</td>\n",
       "      <td>0.117568</td>\n",
       "      <td>0.139725</td>\n",
       "      <td>0.138215</td>\n",
       "      <td>0.174917</td>\n",
       "      <td>0.579642</td>\n",
       "      <td>{'conf_alpha': 1.3997319432813828}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm    Strategy  Number of Optimization Trials  \\\n",
       "0  LMF_factors=100  confidence                             20   \n",
       "\n",
       "   Best Val NDCG@20  Test NDCG@10  Test NDCG@20  Test Precision@10  \\\n",
       "0           0.11609      0.117568      0.139725           0.138215   \n",
       "\n",
       "   Test Precision@20  Final Train Time (s)                         Best Params  \n",
       "0           0.174917              0.579642  {'conf_alpha': 1.3997319432813828}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"log_idf\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:47:56,627] A new study created in memory with name: no-name-bd7bfe21-eae5-4afe-9fc7-5d90e6660970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:01,586] Trial 0 finished with value: 0.10698715095841836 and parameters: {'power_p': 1.0515309700044204}. Best is trial 0 with value: 0.10698715095841836.\n",
      "[I 2026-02-08 11:48:01,622] Trial 4 finished with value: 0.10961850801790703 and parameters: {'power_p': 1.1767693616659802}. Best is trial 4 with value: 0.10961850801790703.\n",
      "[I 2026-02-08 11:48:01,659] Trial 6 finished with value: 0.1135958824711078 and parameters: {'power_p': 0.709907615432767}. Best is trial 6 with value: 0.1135958824711078.\n",
      "[I 2026-02-08 11:48:01,690] Trial 7 finished with value: 0.13189736524836917 and parameters: {'power_p': 0.1427936776274828}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:01,693] Trial 2 finished with value: 0.12692175865201785 and parameters: {'power_p': 0.18753767196098947}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:01,720] Trial 1 finished with value: 0.11666015336075071 and parameters: {'power_p': 1.2218118643528066}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:01,746] Trial 3 finished with value: 0.10983069222584592 and parameters: {'power_p': 1.0799982073880612}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:01,758] Trial 5 finished with value: 0.11546987082682947 and parameters: {'power_p': 0.586677825003886}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:06,828] Trial 8 finished with value: 0.11450627257025603 and parameters: {'power_p': 1.2333987128731316}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,024] Trial 11 finished with value: 0.1137439867039609 and parameters: {'power_p': 0.628210312355991}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,038] Trial 9 finished with value: 0.11398190710674964 and parameters: {'power_p': 0.7729841986114515}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,094] Trial 14 finished with value: 0.11144025769196442 and parameters: {'power_p': 0.7331576665471012}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,106] Trial 10 finished with value: 0.11633881351454643 and parameters: {'power_p': 0.8178154546902116}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,109] Trial 12 finished with value: 0.10943739949022105 and parameters: {'power_p': 1.3167202026000728}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,138] Trial 13 finished with value: 0.10613623473356334 and parameters: {'power_p': 1.185062902409053}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:07,144] Trial 15 finished with value: 0.10946025018425126 and parameters: {'power_p': 1.4423385696035764}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:09,636] Trial 16 finished with value: 0.11082694827637722 and parameters: {'power_p': 1.293468320767743}. Best is trial 7 with value: 0.13189736524836917.\n",
      "[I 2026-02-08 11:48:09,728] Trial 18 finished with value: 0.13699800473436236 and parameters: {'power_p': 0.12019760331996314}. Best is trial 18 with value: 0.13699800473436236.\n",
      "[I 2026-02-08 11:48:09,729] Trial 19 finished with value: 0.1350401705167703 and parameters: {'power_p': 0.10023095845832655}. Best is trial 18 with value: 0.13699800473436236.\n",
      "[I 2026-02-08 11:48:09,743] Trial 17 finished with value: 0.13318241658400687 and parameters: {'power_p': 0.1152995765826053}. Best is trial 18 with value: 0.13699800473436236.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>power</td>\n",
       "      <td>20</td>\n",
       "      <td>0.136998</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>0.159872</td>\n",
       "      <td>0.150256</td>\n",
       "      <td>0.171127</td>\n",
       "      <td>0.641469</td>\n",
       "      <td>{'power_p': 0.12019760331996314}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm Strategy  Number of Optimization Trials  Best Val NDCG@20  \\\n",
       "0  LMF_factors=100    power                             20          0.136998   \n",
       "\n",
       "   Test NDCG@10  Test NDCG@20  Test Precision@10  Test Precision@20  \\\n",
       "0      0.142695      0.159872           0.150256           0.171127   \n",
       "\n",
       "   Final Train Time (s)                       Best Params  \n",
       "0              0.641469  {'power_p': 0.12019760331996314}  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"power\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:11,154] A new study created in memory with name: no-name-220f1ff3-b2a0-4031-b166-9450f4b27b86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with normalized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:11,871] Trial 0 finished with value: 0.14560554872075088 and parameters: {}. Best is trial 0 with value: 0.14560554872075088.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>normalized</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>0.156788</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>0.159327</td>\n",
       "      <td>0.178233</td>\n",
       "      <td>0.60226</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm    Strategy  Number of Optimization Trials  \\\n",
       "0  LMF_factors=100  normalized                              1   \n",
       "\n",
       "   Best Val NDCG@20  Test NDCG@10  Test NDCG@20  Test Precision@10  \\\n",
       "0          0.145606      0.156788      0.171044           0.159327   \n",
       "\n",
       "   Test Precision@20  Final Train Time (s) Best Params  \n",
       "0           0.178233               0.60226          {}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"normalized\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a1e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:13,381] A new study created in memory with name: no-name-979fc17f-ed3c-41b8-82e6-d6fe245e972f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with pmi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:14,102] Trial 0 finished with value: 0.11136221638197882 and parameters: {}. Best is trial 0 with value: 0.11136221638197882.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>pmi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.11663</td>\n",
       "      <td>0.138991</td>\n",
       "      <td>0.130134</td>\n",
       "      <td>0.164969</td>\n",
       "      <td>0.596271</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm Strategy  Number of Optimization Trials  Best Val NDCG@20  \\\n",
       "0  LMF_factors=100      pmi                              1          0.111362   \n",
       "\n",
       "   Test NDCG@10  Test NDCG@20  Test Precision@10  Test Precision@20  \\\n",
       "0       0.11663      0.138991           0.130134           0.164969   \n",
       "\n",
       "   Final Train Time (s) Best Params  \n",
       "0              0.596271          {}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"pmi\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:48:15,539] A new study created in memory with name: no-name-0be3a974-ec33-41d2-984f-df9c7163d4e8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with robust_user_centric...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"robust_user_centric\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896099a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:44:51,078] A new study created in memory with name: no-name-2ab10bd6-f77f-40e0-80ce-a3732164fa40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with robust_user_centric_weight_v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/projects/rec-sys-research/weighting_is_fun/weighting_strategies.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / (1 + np.exp(-z_scores))\n",
      "[I 2026-02-08 11:44:55,959] Trial 1 finished with value: 0.14222767274866804 and parameters: {'lower_q': 44.946864213449814, 'upper_q': 86.61588375369048}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,385] Trial 2 finished with value: 0.13714585698794177 and parameters: {'lower_q': 18.42790712620242, 'upper_q': 55.608139480947784}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,390] Trial 5 finished with value: 0.13742459371698043 and parameters: {'lower_q': 31.8209239006363, 'upper_q': 74.36206492146295}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,405] Trial 0 finished with value: 0.1294827998839493 and parameters: {'lower_q': 9.037524893785452, 'upper_q': 87.33939078156428}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,426] Trial 4 finished with value: 0.1344212878859834 and parameters: {'lower_q': 44.84699378844844, 'upper_q': 66.51380541451267}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,445] Trial 7 finished with value: 0.13100578746815986 and parameters: {'lower_q': 34.2796601755754, 'upper_q': 92.26322688994087}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,451] Trial 6 finished with value: 0.13225567581633088 and parameters: {'lower_q': 25.086440013538525, 'upper_q': 91.45012966660431}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:44:56,522] Trial 3 finished with value: 0.13597392494192265 and parameters: {'lower_q': 22.254986332519774, 'upper_q': 85.03507937479725}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,842] Trial 14 finished with value: 0.1271863620928366 and parameters: {'lower_q': 12.124662665488305, 'upper_q': 68.1307532326308}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,857] Trial 9 finished with value: 0.1325625575416887 and parameters: {'lower_q': 26.124180378230534, 'upper_q': 89.49685234758304}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,887] Trial 11 finished with value: 0.13016123245905548 and parameters: {'lower_q': 37.02650656155139, 'upper_q': 61.091849440345726}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,887] Trial 8 finished with value: 0.13178815990818193 and parameters: {'lower_q': 15.363000564642832, 'upper_q': 77.59468276112467}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,890] Trial 10 finished with value: 0.14138173049751615 and parameters: {'lower_q': 35.586647440707765, 'upper_q': 83.19084071077367}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,892] Trial 15 finished with value: 0.13081626003108573 and parameters: {'lower_q': 11.655536178536172, 'upper_q': 80.97415957249267}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,894] Trial 12 finished with value: 0.12609347964718567 and parameters: {'lower_q': 28.907100367162357, 'upper_q': 68.40030490653999}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:01,895] Trial 13 finished with value: 0.13113751422176217 and parameters: {'lower_q': 13.1936400364674, 'upper_q': 78.42917766731674}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:04,657] Trial 19 finished with value: 0.135315820128833 and parameters: {'lower_q': 44.62957770410984, 'upper_q': 83.21856954835867}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:04,703] Trial 18 finished with value: 0.14162491016210071 and parameters: {'lower_q': 44.58763433135593, 'upper_q': 82.41571184762786}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:04,714] Trial 16 finished with value: 0.1414079457983434 and parameters: {'lower_q': 44.28821416813029, 'upper_q': 80.94701059480676}. Best is trial 1 with value: 0.14222767274866804.\n",
      "[I 2026-02-08 11:45:04,716] Trial 17 finished with value: 0.14009832455221596 and parameters: {'lower_q': 43.870901922772376, 'upper_q': 81.33166047300352}. Best is trial 1 with value: 0.14222767274866804.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>robust_user_centric_weight_v2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>0.143141</td>\n",
       "      <td>0.165339</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.621233</td>\n",
       "      <td>{'lower_q': 44.946864213449814, 'upper_q': 86....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm                       Strategy  \\\n",
       "0  LMF_factors=100  robust_user_centric_weight_v2   \n",
       "\n",
       "   Number of Optimization Trials  Best Val NDCG@20  Test NDCG@10  \\\n",
       "0                             20          0.142228      0.143141   \n",
       "\n",
       "   Test NDCG@20  Test Precision@10  Test Precision@20  Final Train Time (s)  \\\n",
       "0      0.165339           0.150586           0.185457              0.621233   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'lower_q': 44.946864213449814, 'upper_q': 86....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"robust_user_centric_weight_v2\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:45:06,157] A new study created in memory with name: no-name-a551056e-259c-4bb9-b430-29f52764ed31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with sigmoid_propensity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:45:11,156] Trial 3 finished with value: 0.12374954766339684 and parameters: {'p': 1.4509957613294016, 'beta': 0.6585785651836707}. Best is trial 3 with value: 0.12374954766339684.\n",
      "[I 2026-02-08 11:45:11,173] Trial 5 finished with value: 0.1197167948838753 and parameters: {'p': 3.7097370057132393, 'beta': 0.34682747928504254}. Best is trial 3 with value: 0.12374954766339684.\n",
      "[I 2026-02-08 11:45:11,183] Trial 0 finished with value: 0.12920347514101319 and parameters: {'p': 0.5156936594033215, 'beta': 0.3670299134282563}. Best is trial 0 with value: 0.12920347514101319.\n",
      "[I 2026-02-08 11:45:11,259] Trial 1 finished with value: 0.12421977546127613 and parameters: {'p': 2.0757913108950627, 'beta': 0.11085473683532743}. Best is trial 0 with value: 0.12920347514101319.\n",
      "[I 2026-02-08 11:45:11,263] Trial 7 finished with value: 0.12160269850097663 and parameters: {'p': 1.3941599512777827, 'beta': 0.6216201433855186}. Best is trial 0 with value: 0.12920347514101319.\n",
      "[I 2026-02-08 11:45:11,310] Trial 6 finished with value: 0.12076612965942106 and parameters: {'p': 2.4505896673909495, 'beta': 0.5702303825949279}. Best is trial 0 with value: 0.12920347514101319.\n",
      "[I 2026-02-08 11:45:11,338] Trial 4 finished with value: 0.11968839500596058 and parameters: {'p': 3.581183911515898, 'beta': 0.1112636573768252}. Best is trial 0 with value: 0.12920347514101319.\n",
      "[I 2026-02-08 11:45:11,361] Trial 2 finished with value: 0.12937532845877595 and parameters: {'p': 0.6085479960096445, 'beta': 0.40110104453528717}. Best is trial 2 with value: 0.12937532845877595.\n",
      "[I 2026-02-08 11:45:16,123] Trial 8 finished with value: 0.1349972445774955 and parameters: {'p': 0.8086993622380342, 'beta': 0.4220425317481806}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,408] Trial 10 finished with value: 0.12741516941285427 and parameters: {'p': 1.727223812472668, 'beta': 0.13936501217418062}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,411] Trial 15 finished with value: 0.12346185644763878 and parameters: {'p': 1.2012624698802372, 'beta': 0.6391617203817481}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,424] Trial 13 finished with value: 0.13030915882561245 and parameters: {'p': 4.970009729317962, 'beta': 0.6951699620220916}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,492] Trial 9 finished with value: 0.12764798898252133 and parameters: {'p': 1.0200649817010121, 'beta': 0.7855044909183941}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,494] Trial 12 finished with value: 0.11660148653149938 and parameters: {'p': 3.054692691292923, 'beta': 0.3888351956356403}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,545] Trial 11 finished with value: 0.12332287832354616 and parameters: {'p': 0.7583659761823262, 'beta': 0.7114177839423764}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:16,556] Trial 14 finished with value: 0.12893688435430853 and parameters: {'p': 0.4056036734891961, 'beta': 0.022876410243918066}. Best is trial 8 with value: 0.1349972445774955.\n",
      "[I 2026-02-08 11:45:19,061] Trial 16 finished with value: 0.1400299810158007 and parameters: {'p': 1.584174552551136, 'beta': 0.8217331919976317}. Best is trial 16 with value: 0.1400299810158007.\n",
      "[I 2026-02-08 11:45:19,086] Trial 18 finished with value: 0.12782805279449908 and parameters: {'p': 4.955688678960588, 'beta': 0.907145469050055}. Best is trial 16 with value: 0.1400299810158007.\n",
      "[I 2026-02-08 11:45:19,106] Trial 19 finished with value: 0.1362353042274771 and parameters: {'p': 4.977384595009301, 'beta': 0.9378015038754386}. Best is trial 16 with value: 0.1400299810158007.\n",
      "[I 2026-02-08 11:45:19,110] Trial 17 finished with value: 0.11759386613069764 and parameters: {'p': 0.28554337652946926, 'beta': 0.3817254390302064}. Best is trial 16 with value: 0.1400299810158007.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>sigmoid_propensity</td>\n",
       "      <td>20</td>\n",
       "      <td>0.14003</td>\n",
       "      <td>0.145148</td>\n",
       "      <td>0.165106</td>\n",
       "      <td>0.158337</td>\n",
       "      <td>0.183207</td>\n",
       "      <td>0.599144</td>\n",
       "      <td>{'p': 1.584174552551136, 'beta': 0.82173319199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm            Strategy  Number of Optimization Trials  \\\n",
       "0  LMF_factors=100  sigmoid_propensity                             20   \n",
       "\n",
       "   Best Val NDCG@20  Test NDCG@10  Test NDCG@20  Test Precision@10  \\\n",
       "0           0.14003      0.145148      0.165106           0.158337   \n",
       "\n",
       "   Test Precision@20  Final Train Time (s)  \\\n",
       "0           0.183207              0.599144   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'p': 1.584174552551136, 'beta': 0.82173319199...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"sigmoid_propensity\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffc588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:45:20,407] A new study created in memory with name: no-name-4b456f55-39ac-4203-8445-135efda06605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for LMF_factors=100 with power_lift...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 11:45:25,479] Trial 7 finished with value: 0.12665975911493066 and parameters: {'p': 0.18733368672913622}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,548] Trial 6 finished with value: 0.018375867058276235 and parameters: {'p': 1.0853421665358742}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,569] Trial 2 finished with value: 0.11536278852377933 and parameters: {'p': 0.752828961047047}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,604] Trial 3 finished with value: 0.1066529097725081 and parameters: {'p': 0.7711447584390401}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,613] Trial 4 finished with value: 0.11707464605690672 and parameters: {'p': 0.12838678409424592}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,634] Trial 5 finished with value: 0.11583752714337903 and parameters: {'p': 0.11489324855895683}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,638] Trial 1 finished with value: 0.07679763101630431 and parameters: {'p': 0.8809322854870879}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:25,676] Trial 0 finished with value: 0.014953118430862652 and parameters: {'p': 1.1000922051823498}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,770] Trial 13 finished with value: 0.11394381713003437 and parameters: {'p': 0.7044640887588132}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,774] Trial 12 finished with value: 0.12266866123075264 and parameters: {'p': 0.6918782454151746}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,776] Trial 14 finished with value: 0.12261145105205358 and parameters: {'p': 0.7135373696650796}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,788] Trial 9 finished with value: 0.11805441084807249 and parameters: {'p': 0.3370513504571999}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,791] Trial 8 finished with value: 0.011945855048259896 and parameters: {'p': 1.1486372973826666}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,791] Trial 11 finished with value: 0.08401363089301991 and parameters: {'p': 0.8767562082228083}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,794] Trial 10 finished with value: 0.036604609794782285 and parameters: {'p': 0.9741724002482722}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:30,801] Trial 15 finished with value: 0.12262925768156774 and parameters: {'p': 0.4843657811923513}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:33,638] Trial 18 finished with value: 0.005018514831125109 and parameters: {'p': 1.4831357204617752}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:33,638] Trial 16 finished with value: 0.004913757364209339 and parameters: {'p': 1.4803256285388322}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:33,644] Trial 17 finished with value: 0.005488264229696534 and parameters: {'p': 1.4925872086437058}. Best is trial 7 with value: 0.12665975911493066.\n",
      "[I 2026-02-08 11:45:33,648] Trial 19 finished with value: 0.005003786303437572 and parameters: {'p': 1.4952066780142694}. Best is trial 7 with value: 0.12665975911493066.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>power_lift</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12666</td>\n",
       "      <td>0.138709</td>\n",
       "      <td>0.157831</td>\n",
       "      <td>0.146462</td>\n",
       "      <td>0.169588</td>\n",
       "      <td>0.630358</td>\n",
       "      <td>{'p': 0.18733368672913622}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm    Strategy  Number of Optimization Trials  \\\n",
       "0  LMF_factors=100  power_lift                             20   \n",
       "\n",
       "   Best Val NDCG@20  Test NDCG@10  Test NDCG@20  Test Precision@10  \\\n",
       "0           0.12666      0.138709      0.157831           0.146462   \n",
       "\n",
       "   Test Precision@20  Final Train Time (s)                 Best Params  \n",
       "0           0.169588              0.630358  {'p': 0.18733368672913622}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_hyperparameter_optimization(train_mat, val_mat, train_val_mat, test_mat, weighting_strategy=\"power_lift\", algorithm=\"LMF_factors=100\", n_trials=20, output_dir=results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c413de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Number of Optimization Trials</th>\n",
       "      <th>Best Val NDCG@20</th>\n",
       "      <th>Test NDCG@10</th>\n",
       "      <th>Test NDCG@20</th>\n",
       "      <th>Test Precision@10</th>\n",
       "      <th>Test Precision@20</th>\n",
       "      <th>Final Train Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>normalized</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>0.156788</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>0.159327</td>\n",
       "      <td>0.178233</td>\n",
       "      <td>0.580045</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>power</td>\n",
       "      <td>20</td>\n",
       "      <td>0.137803</td>\n",
       "      <td>0.153017</td>\n",
       "      <td>0.169674</td>\n",
       "      <td>0.157843</td>\n",
       "      <td>0.176930</td>\n",
       "      <td>0.631229</td>\n",
       "      <td>{'power_p': 0.12873544599079584}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>robust_user_centric_weight_v2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>0.143141</td>\n",
       "      <td>0.165339</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.621233</td>\n",
       "      <td>{'lower_q': 44.946864213449814, 'upper_q': 86....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>sigmoid_propensity</td>\n",
       "      <td>20</td>\n",
       "      <td>0.140030</td>\n",
       "      <td>0.145148</td>\n",
       "      <td>0.165106</td>\n",
       "      <td>0.158337</td>\n",
       "      <td>0.183207</td>\n",
       "      <td>0.599144</td>\n",
       "      <td>{'p': 1.584174552551136, 'beta': 0.82173319199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>robust_user_centric</td>\n",
       "      <td>20</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.136959</td>\n",
       "      <td>0.161276</td>\n",
       "      <td>0.142009</td>\n",
       "      <td>0.178707</td>\n",
       "      <td>0.675411</td>\n",
       "      <td>{'scale_factor': 0.3177260922068834}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>power_lift</td>\n",
       "      <td>20</td>\n",
       "      <td>0.126660</td>\n",
       "      <td>0.138709</td>\n",
       "      <td>0.157831</td>\n",
       "      <td>0.146462</td>\n",
       "      <td>0.169588</td>\n",
       "      <td>0.630358</td>\n",
       "      <td>{'p': 0.18733368672913622}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>log</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130376</td>\n",
       "      <td>0.137035</td>\n",
       "      <td>0.152675</td>\n",
       "      <td>0.150091</td>\n",
       "      <td>0.173614</td>\n",
       "      <td>0.594178</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123575</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.149315</td>\n",
       "      <td>0.144318</td>\n",
       "      <td>0.180602</td>\n",
       "      <td>0.569084</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>bm25</td>\n",
       "      <td>20</td>\n",
       "      <td>0.124334</td>\n",
       "      <td>0.125421</td>\n",
       "      <td>0.146730</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.175865</td>\n",
       "      <td>0.609846</td>\n",
       "      <td>{'bm25_k1': 970.481333911463, 'bm25_b': 0.0969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>pmi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.116630</td>\n",
       "      <td>0.138991</td>\n",
       "      <td>0.130134</td>\n",
       "      <td>0.164969</td>\n",
       "      <td>0.607751</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>no_weighting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106916</td>\n",
       "      <td>0.117622</td>\n",
       "      <td>0.133865</td>\n",
       "      <td>0.135412</td>\n",
       "      <td>0.164140</td>\n",
       "      <td>0.766930</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMF_factors=100</td>\n",
       "      <td>confidence</td>\n",
       "      <td>20</td>\n",
       "      <td>0.106646</td>\n",
       "      <td>0.101917</td>\n",
       "      <td>0.123045</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.144481</td>\n",
       "      <td>0.576900</td>\n",
       "      <td>{'conf_alpha': 4.001359173656779}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm                       Strategy  \\\n",
       "0  LMF_factors=100                     normalized   \n",
       "0  LMF_factors=100                          power   \n",
       "0  LMF_factors=100  robust_user_centric_weight_v2   \n",
       "0  LMF_factors=100             sigmoid_propensity   \n",
       "0  LMF_factors=100            robust_user_centric   \n",
       "0  LMF_factors=100                     power_lift   \n",
       "0  LMF_factors=100                            log   \n",
       "0  LMF_factors=100                          tfidf   \n",
       "0  LMF_factors=100                           bm25   \n",
       "0  LMF_factors=100                            pmi   \n",
       "0  LMF_factors=100                   no_weighting   \n",
       "0  LMF_factors=100                     confidence   \n",
       "\n",
       "   Number of Optimization Trials  Best Val NDCG@20  Test NDCG@10  \\\n",
       "0                              1          0.145606      0.156788   \n",
       "0                             20          0.137803      0.153017   \n",
       "0                             20          0.142228      0.143141   \n",
       "0                             20          0.140030      0.145148   \n",
       "0                             20          0.145370      0.136959   \n",
       "0                             20          0.126660      0.138709   \n",
       "0                              1          0.130376      0.137035   \n",
       "0                              1          0.123575      0.127691   \n",
       "0                             20          0.124334      0.125421   \n",
       "0                              1          0.111362      0.116630   \n",
       "0                              1          0.106916      0.117622   \n",
       "0                             20          0.106646      0.101917   \n",
       "\n",
       "   Test NDCG@20  Test Precision@10  Test Precision@20  Final Train Time (s)  \\\n",
       "0      0.171044           0.159327           0.178233              0.580045   \n",
       "0      0.169674           0.157843           0.176930              0.631229   \n",
       "0      0.165339           0.150586           0.185457              0.621233   \n",
       "0      0.165106           0.158337           0.183207              0.599144   \n",
       "0      0.161276           0.142009           0.178707              0.675411   \n",
       "0      0.157831           0.146462           0.169588              0.630358   \n",
       "0      0.152675           0.150091           0.173614              0.594178   \n",
       "0      0.149315           0.144318           0.180602              0.569084   \n",
       "0      0.146730           0.139865           0.175865              0.609846   \n",
       "0      0.138991           0.130134           0.164969              0.607751   \n",
       "0      0.133865           0.135412           0.164140              0.766930   \n",
       "0      0.123045           0.113970           0.144481              0.576900   \n",
       "\n",
       "                                         Best Params  \n",
       "0                                                 {}  \n",
       "0                   {'power_p': 0.12873544599079584}  \n",
       "0  {'lower_q': 44.946864213449814, 'upper_q': 86....  \n",
       "0  {'p': 1.584174552551136, 'beta': 0.82173319199...  \n",
       "0               {'scale_factor': 0.3177260922068834}  \n",
       "0                         {'p': 0.18733368672913622}  \n",
       "0                                                 {}  \n",
       "0                                                 {}  \n",
       "0  {'bm25_k1': 970.481333911463, 'bm25_b': 0.0969...  \n",
       "0                                                 {}  \n",
       "0                                                 {}  \n",
       "0                  {'conf_alpha': 4.001359173656779}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "all_results = []\n",
    "# Match any CSV in the result folder\n",
    "for f in glob.glob(f\"{results_folder}/*.csv\"):\n",
    "    all_results.append(pd.read_csv(f))\n",
    "\n",
    "if all_results:\n",
    "    experiment_results = pd.concat(all_results)\n",
    "    experiment_results = experiment_results.sort_values(\"Test NDCG@20\", ascending=False)\n",
    "    experiment_results.to_csv(results_filename, index=False)\n",
    "else:\n",
    "    print(\"No results found.\")\n",
    "\n",
    "experiment_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
