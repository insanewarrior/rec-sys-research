{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(16)\n",
    "torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import MF, PMF, BPR, SANSA, BiVAECF, LightGCN, RecVAE, EASE, NGCF, VAECF, IBPR, NeuMF, HPF, WBPR\n",
    "from cornac.metrics import Precision, Recall, NDCG, MAP, MRR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def stratified_ranking_split(\n",
    "    df: pd.DataFrame,\n",
    "    entity_field: str,\n",
    "    test_size: float = 0.1,\n",
    "    random_state: Optional[int] = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a ranking-based dataset into training and test sets while preserving the entity distribution.\n",
    "\n",
    "    This function is useful for ranking models (e.g., next-best-offer, personalized recommendations) where each\n",
    "    entity (e.g., user) has multiple interactions with different items, and stratification ensures that\n",
    "    different user interaction levels are maintained in both splits.\n",
    "\n",
    "    Parameters:\n",
    "        df: The ranking dataset, where each row represents an interaction between an entity (e.g., user)\n",
    "            and an item (e.g., game, offer).\n",
    "        entity_field: The column representing the entity to be stratified.\n",
    "        test_size: Fraction of unique entities to allocate to the test set.\n",
    "        random_state: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DataFrames containing training and test data.\n",
    "\n",
    "    Example:\n",
    "        >>> train_validation_df, test_df = stratified_ranking_split(df, entity_field='user_id', test_size=0.1)\n",
    "        >>> train_df, validation_df = stratified_ranking_split(\n",
    "        ...     train_validation_df, entity_field='user_id', test_size=0.1\n",
    "        ... )\n",
    "        >>> print(train_df.shape, validation_df.shape, test_df.shape)\n",
    "    \"\"\"\n",
    "    entity_interaction_counts = df[entity_field].value_counts()\n",
    "\n",
    "    interaction_frequencies = entity_interaction_counts.value_counts()\n",
    "    stratifiable_interaction_counts = interaction_frequencies[interaction_frequencies >= 2].index\n",
    "\n",
    "    stratifiable_entities = entity_interaction_counts[\n",
    "        entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "    non_stratifiable_entities = entity_interaction_counts[\n",
    "        ~entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "\n",
    "    train_strat, test_strat = (\n",
    "        train_test_split(\n",
    "            stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            stratify=entity_interaction_counts[stratifiable_entities],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        if len(stratifiable_entities) > 1\n",
    "        else (stratifiable_entities, [])\n",
    "    )\n",
    "\n",
    "    if len(non_stratifiable_entities) > 1:\n",
    "        train_non_strat, test_non_strat = train_test_split(\n",
    "            non_stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        train_non_strat = non_stratifiable_entities\n",
    "        test_non_strat = []\n",
    "\n",
    "    train_users = np.concatenate([train_strat, train_non_strat])\n",
    "    test_users = np.concatenate([test_strat, test_non_strat])\n",
    "\n",
    "    return df[df[entity_field].isin(train_users)], df[df[entity_field].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "metrics = [Precision(k=10), Recall(k=10), NDCG(k=10), MAP(), MRR()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastfm_dataset = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/a-shyraliev/phd/rec-sys-research/collab_filtering_battlefield/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 2, 3],\n",
    "        names=['user_id', 'item_id', 'play_count'],\n",
    "    )\n",
    "    .loc[:, ['user_id', 'item_id', 'play_count']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358868, 292363)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfm_dataset['user_id'].nunique(), lastfm_dataset['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, lastfm_dataset_sample_str = stratified_ranking_split(\n",
    "    lastfm_dataset,\n",
    "    entity_field='user_id',\n",
    "    test_size=0.1,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "del lastfm_dataset, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/data/dataset.py:335: UserWarning: 5 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<35887x93612 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1402848 stored elements in Compressed Sparse Row format>,\n",
       " <35887x93612 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 339585 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RatioSplit(data=lastfm_dataset_sample_str.values, test_size=0.2, rating_threshold=0.0, seed=SEED)\n",
    "rs.train_set.csr_matrix, rs.test_set.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lastfm_dataset_sample_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_models = [\n",
    "    MF(use_bias=True, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "   | MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "-- + --- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "MF | nan | 0.0003 |  0.0000 |       0.0000 |    0.0000 |    0.4127 | 143.9471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=mf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_models = [\n",
    "    PMF(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "PMF | 0.0001 | 0.0001 |  0.0000 |       0.0000 |    0.0000 |   12.6263 | 338.8230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=pmf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_models = [\n",
    "    BPR(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BPR | 0.0273 | 0.1294 |  0.0424 |       0.0343 |    0.0358 |   11.6591 | 451.1734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BiVAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivaecf_models = [\n",
    "    BiVAECF(use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "        |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BiVAECF | 0.0637 | 0.2451 |  0.0930 |       0.0757 |    0.0796 | 7616.4112 | 398.0724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bivaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RecVAE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recvae_models = [\n",
    "    RecVAE(n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "       |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------ + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "RecVae | 0.0763 | 0.2847 |  0.1142 |       0.0925 |    0.0979 | 6903.3554 | 813.5656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=recvae_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EASE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ease_models = [\n",
    "    EASE(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ease_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93,612 × 93,612=8,763,220,944 elements \n",
    "\n",
    "Assuming each float is 8 bytes (float64), that matrix alone would use:\n",
    "8,763,220,944 × 8≈70.1 GB8\n",
    "\n",
    "That’s just one matrix — and there are intermediate copies made during matrix operations, inversion, etc., \n",
    "so actual memory usage can easily balloon to 100–150 GB RAM or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. HPF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_models = [\n",
    "    HPF(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning...\n",
      "Learning completed!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "HPF | 0.0422 | 0.1825 |  0.0641 |       0.0517 |    0.0538 |  370.1086 | 386.1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=hpf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. IBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibpr_models = [\n",
    "    IBPR(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ibpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## too long to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. SANSA hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sansa_models = [\n",
    "    SANSA(verbose=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 1.0*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (93612, 93612) \n",
      "                    nnz = 26274852 \n",
      "                    density = 0.299831% \n",
      "                    size = 210.6 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.7384495735168457, relative Frobenius norm squared: 0.0034407598432153463\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.7384495735168457, relative Frobenius norm squared: 0.0034407598432153463\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.30587220191955566, relative Frobenius norm squared: 0.002833602949976921\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05642279237508774, relative Frobenius norm squared: 0.00020451104501262307\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05089490860700607, relative Frobenius norm squared: 0.00020405171380843967\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.0002033205673797056\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.0002026166912401095\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.0002020141255343333\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.00020147187751717865\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.00020095818035770208\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.0002004981943173334\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.00020001937809865922\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.0001995885104406625\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 0.05033910647034645, relative Frobenius norm squared: 0.00019916935707442462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "----- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "SANSA | 0.0659 | 0.2583 |  0.1029 |       0.0832 |    0.0880 |  584.8892 | 786.6559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=sansa_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. VAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaecf_models = [\n",
    "    VAECF(use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "----- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "VAECF | 0.0675 | 0.2632 |  0.1019 |       0.0809 |    0.0851 | 3870.0494 | 498.0539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=vaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. NeuMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_models = [\n",
    "    NeuMF(verbose=False, backend=\"pytorch\", seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "----- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "NeuMF | 0.0459 | 0.1531 |  0.0567 |       0.0503 |    0.0529 | 1231.0541 | 616.6095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=neumf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. LightGCN hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn_models = [\n",
    "    LightGCN(verbose=False, num_epochs=10, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "         |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 |  Train (s) |  Test (s)\n",
      "-------- + ------ + ------ + ------- + ------------ + --------- + ---------- + ---------\n",
      "LightGCN | 0.0538 | 0.2174 |  0.0799 |       0.0647 |    0.0677 | 20095.9606 | 1072.9381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=lightgcn_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. NGCF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngcf_models = [\n",
    "    NGCF(verbose=False, num_epochs=10, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcornac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngcf_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/experiment/experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 142\u001b[0m     test_result, val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mappend(test_result)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/eval_methods/base_method.py:734\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[0;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] Training started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    733\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 734\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# EVALUATION #\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/ngcf/recom_ngcf.py:173\u001b[0m, in \u001b[0;36mNGCF.fit\u001b[0;34m(self, train_set, val_set)\u001b[0m\n\u001b[1;32m    161\u001b[0m accum_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_u, batch_i, batch_j \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    163\u001b[0m     train_set\u001b[38;5;241m.\u001b[39muij_iter(\n\u001b[1;32m    164\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    172\u001b[0m ):\n\u001b[0;32m--> 173\u001b[0m     u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_j\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     batch_loss, batch_bpr_loss, batch_reg_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_fn(\n\u001b[1;32m    178\u001b[0m         u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     accum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_u)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/ngcf/ngcf.py:158\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, g, users, pos_items, neg_items)\u001b[0m\n\u001b[1;32m    156\u001b[0m item_embeds\u001b[38;5;241m.\u001b[39mappend(h_dict[ITEM_KEY])\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 158\u001b[0m     h_dict \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     user_embeds\u001b[38;5;241m.\u001b[39mappend(h_dict[USER_KEY])\n\u001b[1;32m    160\u001b[0m     item_embeds\u001b[38;5;241m.\u001b[39mappend(h_dict[ITEM_KEY])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/ngcf/ngcf.py:91\u001b[0m, in \u001b[0;36mNGCFLayer.forward\u001b[0;34m(self, g, feat_dict)\u001b[0m\n\u001b[1;32m     83\u001b[0m         g\u001b[38;5;241m.\u001b[39medges[(srctype, etype, dsttype)]\u001b[38;5;241m.\u001b[39mdata[\n\u001b[1;32m     84\u001b[0m             etype\n\u001b[1;32m     85\u001b[0m         ] \u001b[38;5;241m=\u001b[39m messages  \u001b[38;5;66;03m# store in edata\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         funcs[(srctype, etype, dsttype)] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m             fn\u001b[38;5;241m.\u001b[39mcopy_e(etype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     88\u001b[0m             fn\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     89\u001b[0m         )  \u001b[38;5;66;03m# define message and reduce functions\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_update_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# update all, reduce by first type-wisely then across different types\u001b[39;00m\n\u001b[1;32m     94\u001b[0m feature_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ntype \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mntypes:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/heterograph.py:5259\u001b[0m, in \u001b[0;36mDGLGraph.multi_update_all\u001b[0;34m(self, etype_dict, cross_reducer, apply_node_func)\u001b[0m\n\u001b[1;32m   5257\u001b[0m     mfunc, rfunc, afunc \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m   5258\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[etype]\n\u001b[0;32m-> 5259\u001b[0m     all_out[dtid]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_passing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafunc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5260\u001b[0m     merge_order[dtid]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   5261\u001b[0m         etid\n\u001b[1;32m   5262\u001b[0m     )  \u001b[38;5;66;03m# use edge type id as merge order hint\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtid, frames \u001b[38;5;129;01min\u001b[39;00m all_out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   5264\u001b[0m     \u001b[38;5;66;03m# merge by cross_reducer\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/core.py:398\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke message passing computation on the whole graph.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    Results from the message passing computation.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    392\u001b[0m     is_builtin(mfunc)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_builtin(rfunc)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m ):\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# invoke fused message passing\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     ndata \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# invoke message passing in two separate steps\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# message phase\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_builtin(mfunc):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/core.py:368\u001b[0m, in \u001b[0;36minvoke_gspmm\u001b[0;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# \"copy_e\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m             x \u001b[38;5;241m=\u001b[39m data_dict_to_list(graph, x, mfunc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 368\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {rfunc\u001b[38;5;241m.\u001b[39mout_field: z}\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/ops/spmm.py:217\u001b[0m, in \u001b[0;36m_gen_copy_reduce_func.<locals>.func\u001b[0;34m(g, x)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gspmm(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_lhs\u001b[39m\u001b[38;5;124m\"\u001b[39m, reduce_op, x, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy_rhs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/ops/spmm.py:79\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m     77\u001b[0m         lhs_data, rhs_data \u001b[38;5;241m=\u001b[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# With max and min reducers infinity will be returned for zero degree nodes\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mgspmm_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     lhs_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     89\u001b[0m         [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m g\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mnumber_of_ntypes()\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lhs_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m lhs_data\n\u001b[1;32m     92\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/backend/pytorch/sparse.py:1032\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m   1030\u001b[0m args \u001b[38;5;241m=\u001b[39m _cast_if_autocast_enabled(gidx, op, reduce_op, lhs_data, rhs_data)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _disable_autocast_if_enabled():\n\u001b[0;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGSpMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/backend/pytorch/sparse.py:165\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[0;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[0;32m--> 165\u001b[0m     out, (argX, argY) \u001b[38;5;241m=\u001b[39m \u001b[43m_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     reduce_last \u001b[38;5;241m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[1;32m    167\u001b[0m     X_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/_sparse_ops.py:239\u001b[0m, in \u001b[0;36m_gspmm\u001b[0;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[1;32m    237\u001b[0m arg_e_nd \u001b[38;5;241m=\u001b[39m to_dgl_nd_for_write(arg_e)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gidx\u001b[38;5;241m.\u001b[39mnum_edges(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[43m_CAPI_DGLKernelSpMM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_u\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_e\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_dgl_nd_for_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_u_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_e_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# arg_* should have already been changed. But we found this doesn't work\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# The workaround is proposed by Jinjing, and we still need to investigate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# where the problem is.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m arg_u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m arg_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dgl/_ffi/_ctypes/function.py:213\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    210\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m DGLValue()\n\u001b[1;32m    211\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[1;32m    212\u001b[0m check_call(\n\u001b[0;32m--> 213\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDGLFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    222\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n\u001b[1;32m    223\u001b[0m _ \u001b[38;5;241m=\u001b[39m args\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ngcf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "won't finish, too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. WBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbpr_models = [\n",
    "    WBPR(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "     |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "---- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "WBPR | 0.0024 | 0.0151 |  0.0037 |       0.0033 |    0.0034 |   11.5198 | 363.8079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=wbpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************** [START] **************************\n",
      "Runing on cpu.\n",
      "Total steps 281\n",
      "Epoch: 1/5; nmse_train: 0.0; cosine_train: 0.8837; training time: 43.314320s3.314159s\n",
      "Epoch: 2/5; nmse_train: 0.0; cosine_train: 0.839; training time: 43.276342s.276242s6s\n",
      "Epoch: 3/5; nmse_train: 0.0; cosine_train: 0.8272; training time: 43.718410s3.718304s\n",
      "Epoch: 4/5; nmse_train: 0.0; cosine_train: 0.8211; training time: 44.072291s4.072195s\n",
      "Epoch: 5/5; nmse_train: 0.0; cosine_train: 0.8167; training time: 44.138961s4.138862s\n",
      "\n",
      "************************** [END] **************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nmse_train': [np.float64(1.8880895251537476e-05),\n",
       "  np.float64(1.7924249936367494e-05),\n",
       "  np.float64(1.7673339722651135e-05),\n",
       "  np.float64(1.754322696395974e-05),\n",
       "  np.float64(1.7448970143810856e-05)],\n",
       " 'cosine_train': [np.float64(0.8837340938072781),\n",
       "  np.float64(0.8389571728814539),\n",
       "  np.float64(0.8272125980289805),\n",
       "  np.float64(0.8211221527374511),\n",
       "  np.float64(0.816709994792514)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elsa import ELSA\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "items_cnt = rs.train_set.csr_matrix.shape[1]\n",
    "factors = 256 \n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = ELSA(n_items=items_cnt, device=device, n_dims=factors)\n",
    "\n",
    "model.fit(rs.train_set.csr_matrix, batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "# # save item embeddings into np array\n",
    "A = torch.nn.functional.normalize(model.get_items_embeddings(), dim=-1).cpu().numpy()\n",
    "\n",
    "# # get predictions in PyTorch\n",
    "# predictions = model.predict(rs.test_set.csr_matrix, batch_size=batch_size)\n",
    "\n",
    "# # get predictions in numpy\n",
    "# predictions = ((rs.test_set.csr_matrix @ A) @ (A.T)) - rs.test_set.csr_matrix\n",
    "\n",
    "predictions = model.predict(rs.test_set.csr_matrix, batch_size=batch_size).numpy()\n",
    "predictions_idx = (-predictions).argsort()\n",
    "predictions_idx = np.array(rs.test_set.item_ids)[predictions_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
