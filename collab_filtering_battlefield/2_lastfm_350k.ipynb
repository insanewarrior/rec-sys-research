{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(16)\n",
    "torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import MF, PMF, BPR, SANSA, BiVAECF, LightGCN, RecVAE, EASE, NGCF, VAECF, IBPR, NeuMF, HPF\n",
    "from cornac.metrics import Precision, Recall, NDCG, MAP, MRR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_ranking_split(\n",
    "    df: pd.DataFrame,\n",
    "    entity_field: str,\n",
    "    test_size: float = 0.1,\n",
    "    random_state: int | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a ranking-based dataset into training and test sets while preserving the entity distribution.\n",
    "\n",
    "    This function is useful for ranking models (e.g., next-best-offer, personalized recommendations) where each\n",
    "    entity (e.g., user) has multiple interactions with different items, and stratification ensures that\n",
    "    different user interaction levels are maintained in both splits.\n",
    "\n",
    "    Parameters:\n",
    "        df: The ranking dataset, where each row represents an interaction between an entity (e.g., user)\n",
    "            and an item (e.g., game, offer).\n",
    "        entity_field: The column representing the entity to be stratified.\n",
    "        test_size: Fraction of unique entities to allocate to the test set.\n",
    "        random_state: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DataFrames containing training and test data.\n",
    "\n",
    "    Example:\n",
    "        >>> train_validation_df, test_df = stratified_ranking_split(df, entity_field='user_id', test_size=0.1)\n",
    "        >>> train_df, validation_df = stratified_ranking_split(\n",
    "        ...     train_validation_df, entity_field='user_id', test_size=0.1\n",
    "        ... )\n",
    "        >>> print(train_df.shape, validation_df.shape, test_df.shape)\n",
    "    \"\"\"\n",
    "    entity_interaction_counts = df[entity_field].value_counts()\n",
    "\n",
    "    interaction_frequencies = entity_interaction_counts.value_counts()\n",
    "    stratifiable_interaction_counts = interaction_frequencies[interaction_frequencies >= 2].index\n",
    "\n",
    "    stratifiable_entities = entity_interaction_counts[\n",
    "        entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "    non_stratifiable_entities = entity_interaction_counts[\n",
    "        ~entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "\n",
    "    train_strat, test_strat = (\n",
    "        train_test_split(\n",
    "            stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            stratify=entity_interaction_counts[stratifiable_entities],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        if len(stratifiable_entities) > 1\n",
    "        else (stratifiable_entities, [])\n",
    "    )\n",
    "\n",
    "    if len(non_stratifiable_entities) > 1:\n",
    "        train_non_strat, test_non_strat = train_test_split(\n",
    "            non_stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        train_non_strat = non_stratifiable_entities\n",
    "        test_non_strat = []\n",
    "\n",
    "    train_users = np.concatenate([train_strat, train_non_strat])\n",
    "    test_users = np.concatenate([test_strat, test_non_strat])\n",
    "\n",
    "    return df[df[entity_field].isin(train_users)], df[df[entity_field].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "metrics = [Precision(k=10), Recall(k=10), NDCG(k=10), MAP(), MRR()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastfm_dataset = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/a-shyraliev/phd/rec-sys-research/collab_filtering_battlefield/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        usecols=[0, 2, 3],\n",
    "        names=['user_id', 'item_id', 'play_count'],\n",
    "    )\n",
    "    .loc[:, ['user_id', 'item_id', 'play_count']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358868, 292363)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfm_dataset['user_id'].nunique(), lastfm_dataset['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, lastfm_dataset_sample_str = stratified_ranking_split(\n",
    "    lastfm_dataset,\n",
    "    entity_field='user_id',\n",
    "    test_size=0.1,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "del lastfm_dataset, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/data/dataset.py:335: UserWarning: 5 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<35887x93612 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1402848 stored elements in Compressed Sparse Row format>,\n",
       " <35887x93612 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 339585 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RatioSplit(data=lastfm_dataset_sample_str.values, test_size=0.2, rating_threshold=0.0, seed=SEED)\n",
    "rs.train_set.csr_matrix, rs.test_set.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lastfm_dataset_sample_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_models = [\n",
    "    MF(use_bias=True, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "   | MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "-- + --- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "MF | nan | 0.0003 |  0.0000 |       0.0000 |    0.0000 |    0.4127 | 143.9471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=mf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_models = [\n",
    "    PMF(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "PMF | 0.0001 | 0.0001 |  0.0000 |       0.0000 |    0.0000 |   12.6263 | 338.8230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=pmf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_models = [\n",
    "    BPR(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BPR | 0.0273 | 0.1294 |  0.0424 |       0.0343 |    0.0358 |   11.6591 | 451.1734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BiVAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivaecf_models = [\n",
    "    BiVAECF(use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "        |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BiVAECF | 0.0637 | 0.2451 |  0.0930 |       0.0757 |    0.0796 | 7616.4112 | 398.0724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bivaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RecVAE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recvae_models = [\n",
    "    RecVAE(n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "       |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------ + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "RecVae | 0.0763 | 0.2847 |  0.1142 |       0.0925 |    0.0979 | 6903.3554 | 813.5656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=recvae_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EASE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ease_models = [\n",
    "    EASE(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ease_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. HPF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_models = [\n",
    "    HPF(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning...\n",
      "Learning completed!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "    |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "HPF | 0.0422 | 0.1825 |  0.0641 |       0.0517 |    0.0538 |  370.1086 | 386.1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=hpf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. IBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibpr_models = [\n",
    "    IBPR(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[43mcornac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibpr_models\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m----> 7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/experiment/experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n",
      "\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n",
      "\u001b[0;32m--> 142\u001b[0m     test_result, val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mappend(test_result)\n",
      "\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/eval_methods/base_method.py:734\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[0;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n",
      "\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] Training started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;32m    733\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;32m--> 734\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    735\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n",
      "\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# EVALUATION #\u001b[39;00m\n",
      "\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/models/ibpr/recom_ibpr.py:113\u001b[0m, in \u001b[0;36mIBPR.fit\u001b[0;34m(self, train_set, val_set)\u001b[0m\n",
      "\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mibpr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ibpr\n",
      "\u001b[0;32m--> 113\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mibpr\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlamda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/models/ibpr/ibpr.py:59\u001b[0m, in \u001b[0;36mibpr\u001b[0;34m(train_set, k, lamda, n_epochs, learning_rate, batch_size, init_params, verbose)\u001b[0m\n",
      "\u001b[1;32m     52\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;32m     53\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\n",
      "\u001b[1;32m     54\u001b[0m     total\u001b[38;5;241m=\u001b[39mtrain_set\u001b[38;5;241m.\u001b[39mnum_batches(batch_size),\n",
      "\u001b[1;32m     55\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, n_epochs),\n",
      "\u001b[1;32m     56\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose,\n",
      "\u001b[1;32m     57\u001b[0m )\n",
      "\u001b[0;32m---> 59\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muij_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregU\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregI\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/data/dataset.py:524\u001b[0m, in \u001b[0;36mDataset.uij_iter\u001b[0;34m(self, batch_size, shuffle, neg_sampling)\u001b[0m\n",
      "\u001b[1;32m    522\u001b[0m     neg_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice(neg_population)\n",
      "\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdok_matrix[user, neg_item] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m pos_rating:\n",
      "\u001b[0;32m--> 524\u001b[0m         neg_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_population\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    525\u001b[0m     batch_neg_items[i] \u001b[38;5;241m=\u001b[39m neg_item\n",
      "\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m batch_users, batch_pos_items, batch_neg_items\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ibpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. SANSA hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sansa_models = [\n",
    "    SANSA(verbose=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 1.0*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (93612, 93612) \n",
      "                    nnz = 26274852 \n",
      "                    density = 0.299831% \n",
      "                    size = 210.6 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.7384495735168457, relative Frobenius norm squared: 0.0034407598432153463\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.7384495735168457, relative Frobenius norm squared: 0.0034407598432153463\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.30587220191955566, relative Frobenius norm squared: 0.002833602949976921\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=sansa_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. VAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaecf_models = [\n",
    "    VAECF(use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=vaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize models, here we are comparing: Biased MF, PMF, and BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/1_/vlsk20bs5c15fv226p4j88j40000gp/T/ipykernel_9669/2856580991.py\", line 39, in <module>\n",
      "    recvae = RecVAE(\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/cornac/models/recvae/recom_recvae.py\", line 120, in __init__\n",
      "    import torch\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/a-shyraliev/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# mf = MF(k=10, max_iter=200, learning_rate=0.01, lambda_reg=0.02, use_bias=True, seed=123)\n",
    "# pmf = PMF(k=10, max_iter=200, learning_rate=0.001, lambda_reg=0.001, seed=123)\n",
    "# bpr = BPR(k=10, max_iter=200, learning_rate=0.001, lambda_reg=0.01, seed=123)\n",
    "# sansa_cholmod = SANSA(\n",
    "#     name=\"SANSA (CHOLMOD)\",\n",
    "#     l2=500.0,\n",
    "#     weight_matrix_density=1e-2,\n",
    "#     compute_gramian=True,\n",
    "#     factorizer_class=\"CHOLMOD\",\n",
    "#     factorizer_shift_step=1e-3,\n",
    "#     factorizer_shift_multiplier=2.0,\n",
    "#     inverter_scans=5,\n",
    "#     inverter_finetune_steps=20,\n",
    "#     use_absolute_value_scores=False,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "# sansa_icf = SANSA(\n",
    "#     name=\"SANSA (ICF)\",\n",
    "#     l2=10.0,\n",
    "#     weight_matrix_density=1e-2,\n",
    "#     compute_gramian=True,\n",
    "#     factorizer_class=\"ICF\",\n",
    "#     factorizer_shift_step=1e-3,\n",
    "#     factorizer_shift_multiplier=2.0,\n",
    "#     inverter_scans=5,\n",
    "#     inverter_finetune_steps=20,\n",
    "#     use_absolute_value_scores=False,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "# bivaecf = BiVAECF(\n",
    "#     k=10,\n",
    "#     use_gpu=False,\n",
    "# )\n",
    "\n",
    "lightgcn = LightGCN()\n",
    "\n",
    "# recvae = RecVAE(\n",
    "#     use_gpu=False,\n",
    "# )\n",
    "\n",
    "# ease = EASE()\n",
    "\n",
    "ngcf = NGCF()\n",
    "\n",
    "# vaecf = VAECF(\n",
    "#     use_gpu=False,\n",
    "# )\n",
    "\n",
    "# ibpr = IBPR()\n",
    "\n",
    "neumf = NeuMF()\n",
    "\n",
    "# hpf = HPF()\n",
    "\n",
    "models = [sansa_cholmod, sansa_icf, mf, pmf, bpr, bivaecf, recvae, ease, vaecf, ibpr, neumf, hpf]# lightgcn, ngcf]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
