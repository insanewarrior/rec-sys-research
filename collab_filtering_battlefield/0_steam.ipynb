{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(16)\n",
    "torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import MF, PMF, BPR, SANSA, BiVAECF, LightGCN, RecVAE, EASE, NGCF, VAECF, IBPR, NeuMF, HPF\n",
    "from cornac.metrics import Precision, Recall, NDCG, MAP, MRR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_ranking_split(\n",
    "    df: pd.DataFrame,\n",
    "    entity_field: str,\n",
    "    test_size: float = 0.1,\n",
    "    random_state: int | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a ranking-based dataset into training and test sets while preserving the entity distribution.\n",
    "\n",
    "    This function is useful for ranking models (e.g., next-best-offer, personalized recommendations) where each\n",
    "    entity (e.g., user) has multiple interactions with different items, and stratification ensures that\n",
    "    different user interaction levels are maintained in both splits.\n",
    "\n",
    "    Parameters:\n",
    "        df: The ranking dataset, where each row represents an interaction between an entity (e.g., user)\n",
    "            and an item (e.g., game, offer).\n",
    "        entity_field: The column representing the entity to be stratified.\n",
    "        test_size: Fraction of unique entities to allocate to the test set.\n",
    "        random_state: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DataFrames containing training and test data.\n",
    "\n",
    "    Example:\n",
    "        >>> train_validation_df, test_df = stratified_ranking_split(df, entity_field='user_id', test_size=0.1)\n",
    "        >>> train_df, validation_df = stratified_ranking_split(\n",
    "        ...     train_validation_df, entity_field='user_id', test_size=0.1\n",
    "        ... )\n",
    "        >>> print(train_df.shape, validation_df.shape, test_df.shape)\n",
    "    \"\"\"\n",
    "    entity_interaction_counts = df[entity_field].value_counts()\n",
    "\n",
    "    interaction_frequencies = entity_interaction_counts.value_counts()\n",
    "    stratifiable_interaction_counts = interaction_frequencies[interaction_frequencies >= 2].index\n",
    "\n",
    "    stratifiable_entities = entity_interaction_counts[\n",
    "        entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "    non_stratifiable_entities = entity_interaction_counts[\n",
    "        ~entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "\n",
    "    train_strat, test_strat = (\n",
    "        train_test_split(\n",
    "            stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            stratify=entity_interaction_counts[stratifiable_entities],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        if len(stratifiable_entities) > 1\n",
    "        else (stratifiable_entities, [])\n",
    "    )\n",
    "\n",
    "    if len(non_stratifiable_entities) > 1:\n",
    "        train_non_strat, test_non_strat = train_test_split(\n",
    "            non_stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        train_non_strat = non_stratifiable_entities\n",
    "        test_non_strat = []\n",
    "\n",
    "    train_users = np.concatenate([train_strat, train_non_strat])\n",
    "    test_users = np.concatenate([test_strat, test_non_strat])\n",
    "\n",
    "    return df[df[entity_field].isin(train_users)], df[df[entity_field].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "metrics = [Precision(k=10), Recall(k=10), NDCG(k=10), MAP(), MRR()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_dataset = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/a-shyraliev/phd/rec-sys-research/collab_filtering_battlefield/steam_recommendations.csv\",\n",
    "        usecols=['user_id', 'app_id', 'hours'],\n",
    "    )\n",
    "    .loc[:, ['user_id', 'app_id', 'hours']]\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13781059, 37610)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_dataset['user_id'].nunique(), steam_dataset['app_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, steam_dataset_sample_str = stratified_ranking_split(\n",
    "    steam_dataset,\n",
    "    entity_field='user_id',\n",
    "    test_size=0.01,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "del steam_dataset, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<121521x14807 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 325828 stored elements in Compressed Sparse Row format>,\n",
       " <121521x14807 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 62707 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RatioSplit(data=steam_dataset_sample_str.values, test_size=0.2, rating_threshold=0.0, seed=SEED)\n",
    "rs.train_set.csr_matrix, rs.test_set.csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_models = [\n",
    "    MF(name='MF k=10, lambda_reg=0.02', k=10, max_iter=200, lambda_reg=0.02, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=50, lambda_reg=0.02', k=50, max_iter=200, lambda_reg=0.02, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=100, lambda_reg=0.02', k=100, max_iter=200, lambda_reg=0.02, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=10, lambda_reg=0.1', k=10, max_iter=200, lambda_reg=0.1, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=50, lambda_reg=0.1', k=50, max_iter=200, lambda_reg=0.1, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=100, lambda_reg=0.1', k=100, max_iter=200, lambda_reg=0.1, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=10, lambda_reg=1', k=10, max_iter=200, lambda_reg=1, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=50, lambda_reg=1', k=50, max_iter=200, lambda_reg=1, use_bias=True, seed=SEED),\n",
    "    MF(name='MF k=100, lambda_reg=1', k=100, max_iter=200, lambda_reg=1, use_bias=True, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                          | MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------- + --- + ------- + ------------ + --------- + --------- + --------\n",
      "MF k=10, lambda_reg=0.02  | nan |  0.0001 |       0.0000 |    0.0003 |    0.6121 |  21.6584\n",
      "MF k=50, lambda_reg=0.02  | nan |  0.0001 |       0.0000 |    0.0003 |    1.4565 |  31.7773\n",
      "MF k=100, lambda_reg=0.02 | nan |  0.0001 |       0.0000 |    0.0003 |    4.6947 |  30.5076\n",
      "MF k=10, lambda_reg=0.1   | nan |  0.0001 |       0.0000 |    0.0003 |    0.5838 |  21.4168\n",
      "MF k=50, lambda_reg=0.1   | nan |  0.0001 |       0.0000 |    0.0003 |    1.4895 |  32.6081\n",
      "MF k=100, lambda_reg=0.1  | nan |  0.0001 |       0.0000 |    0.0003 |    5.0005 |  32.5445\n",
      "MF k=10, lambda_reg=1     | nan |  0.0001 |       0.0000 |    0.0003 |    0.6227 |  21.9549\n",
      "MF k=50, lambda_reg=1     | nan |  0.0001 |       0.0000 |    0.0003 |    1.6991 |  32.9640\n",
      "MF k=100, lambda_reg=1    | nan |  0.0001 |       0.0000 |    0.0003 |    3.8201 |  32.2801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=mf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_models = [\n",
    "    PMF(name='PMF k=5, lambda_reg=0.001', k=5, max_iter=200, lambda_reg=0.001, seed=SEED),\n",
    "    PMF(name='PMF k=10, lambda_reg=0.001', k=10, max_iter=200, lambda_reg=0.001, seed=SEED),\n",
    "    PMF(name='PMF k=15, lambda_reg=0.001', k=15, max_iter=200, lambda_reg=0.001, seed=SEED),\n",
    "    PMF(name='PMF k=5, lambda_reg=0.1', k=5, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    PMF(name='PMF k=10, lambda_reg=0.1', k=10, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    PMF(name='PMF k=15, lambda_reg=0.1', k=15, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    PMF(name='PMF k=5, lambda_reg=1', k=5, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "    PMF(name='PMF k=10, lambda_reg=1', k=10, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "    PMF(name='PMF k=15, lambda_reg=1', k=15, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                           |    MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "-------------------------- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "PMF k=5, lambda_reg=0.001  | 0.0019 |  0.0019 |       0.0005 |    0.0039 |    5.5292 |  44.1669\n",
      "PMF k=10, lambda_reg=0.001 | 0.0017 |  0.0017 |       0.0005 |    0.0036 |    9.4754 |  47.0882\n",
      "PMF k=15, lambda_reg=0.001 | 0.0008 |  0.0005 |       0.0001 |    0.0011 |   14.2352 |  45.9387\n",
      "PMF k=5, lambda_reg=0.1    | 0.0007 |  0.0000 |       0.0000 |    0.0000 |    5.2613 |  45.3645\n",
      "PMF k=10, lambda_reg=0.1   | 0.0007 |  0.0000 |       0.0000 |    0.0000 |   10.0980 |  47.8467\n",
      "PMF k=15, lambda_reg=0.1   | 0.0007 |  0.0000 |       0.0000 |    0.0000 |   14.9663 |  47.6700\n",
      "PMF k=5, lambda_reg=1      | 0.0006 |  0.0002 |       0.0001 |    0.0005 |    5.5415 |  45.5808\n",
      "PMF k=10, lambda_reg=1     | 0.0008 |  0.0004 |       0.0001 |    0.0006 |   10.5913 |  47.4731\n",
      "PMF k=15, lambda_reg=1     | 0.0008 |  0.0003 |       0.0001 |    0.0005 |   13.9640 |  46.6447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=pmf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_models = [\n",
    "    BPR(name='BPR k=10, lambda_reg=0.01', k=10, max_iter=200, lambda_reg=0.01, seed=SEED),\n",
    "    BPR(name='BPR k=50, lambda_reg=0.01', k=50, max_iter=200, lambda_reg=0.01, seed=SEED),\n",
    "    BPR(name='BPR k=100, lambda_reg=0.01', k=100, max_iter=200, lambda_reg=0.01, seed=SEED),\n",
    "    BPR(name='BPR k=10, lambda_reg=0.1', k=10, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    BPR(name='BPR k=50, lambda_reg=0.1', k=50, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    BPR(name='BPR k=100, lambda_reg=0.1', k=100, max_iter=200, lambda_reg=0.1, seed=SEED),\n",
    "    BPR(name='BPR k=10, lambda_reg=1', k=10, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "    BPR(name='BPR k=50, lambda_reg=1', k=50, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "    BPR(name='BPR k=100, lambda_reg=1', k=100, max_iter=200, lambda_reg=1, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                           |    MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "-------------------------- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BPR k=10, lambda_reg=0.01  | 0.0308 |  0.0312 |       0.0092 |    0.0561 |    3.9516 |  45.1212\n",
      "BPR k=50, lambda_reg=0.01  | 0.0309 |  0.0316 |       0.0094 |    0.0575 |    8.2983 |  57.4187\n",
      "BPR k=100, lambda_reg=0.01 | 0.0307 |  0.0313 |       0.0093 |    0.0566 |   11.7384 |  57.0230\n",
      "BPR k=10, lambda_reg=0.1   | 0.0307 |  0.0310 |       0.0090 |    0.0554 |    4.2672 |  47.3254\n",
      "BPR k=50, lambda_reg=0.1   | 0.0303 |  0.0308 |       0.0091 |    0.0565 |    8.4085 |  57.3794\n",
      "BPR k=100, lambda_reg=0.1  | 0.0281 |  0.0283 |       0.0087 |    0.0544 |   12.1549 |  55.3509\n",
      "BPR k=10, lambda_reg=1     | 0.0300 |  0.0307 |       0.0092 |    0.0560 |    3.9472 |  44.8775\n",
      "BPR k=50, lambda_reg=1     | 0.0299 |  0.0289 |       0.0081 |    0.0509 |    7.5961 |  52.7927\n",
      "BPR k=100, lambda_reg=1    | 0.0284 |  0.0291 |       0.0088 |    0.0550 |   10.7632 |  51.5316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BiVAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivaecf_models = [\n",
    "    BiVAECF(name='BiVAECF k=10, encoder_structure=[20]', k=10, encoder_structure=[20], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    BiVAECF(name='BiVAECF k=20, encoder_structure=[20]', k=50, encoder_structure=[20], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    BiVAECF(name='BiVAECF k=30, encoder_structure=[20]', k=100, encoder_structure=[20], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    BiVAECF(name='BiVAECF k=10, encoder_structure=[40]', k=10, encoder_structure=[40], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    BiVAECF(name='BiVAECF k=50, encoder_structure=[40]', k=50, encoder_structure=[40], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    BiVAECF(name='BiVAECF k=100, encoder_structure=[40]', k=100, encoder_structure=[40], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                      |    MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------------------- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BiVAECF k=10, encoder_structure=[20]  | 0.0167 |  0.0151 |       0.0044 |    0.0279 |  379.0551 |  47.1337\n",
      "BiVAECF k=20, encoder_structure=[20]  | 0.0122 |  0.0094 |       0.0029 |    0.0183 |  350.1261 |  47.3764\n",
      "BiVAECF k=30, encoder_structure=[20]  | 0.0053 |  0.0049 |       0.0020 |    0.0106 |  363.0580 |  47.1756\n",
      "BiVAECF k=10, encoder_structure=[40]  | 0.0126 |  0.0131 |       0.0035 |    0.0221 |  355.6089 |  44.8915\n",
      "BiVAECF k=50, encoder_structure=[40]  | 0.0091 |  0.0090 |       0.0035 |    0.0186 |  359.7766 |  47.6155\n",
      "BiVAECF k=100, encoder_structure=[40] | 0.0076 |  0.0083 |       0.0029 |    0.0145 |  371.4512 |  46.8471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bivaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RecVAE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recvae_models = [\n",
    "    RecVAE(name='RecVAE hidden_dim=600, latent_dim=200', hidden_dim=600, latent_dim=200, n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "RecVAE hidden_dim=600, latent_dim=200 | 0.0304 | 0.0463 |  0.0339 |       0.0107 |    0.0585 | 4152.2937 | 118.4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=recvae_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EASE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ease_models = [\n",
    "    EASE(name='EASE lamb=500, posB=True', lamb=500, posB=True, seed=SEED),\n",
    "    EASE(name='EASE lamb=300, posB=True', lamb=300, posB=True, seed=SEED),\n",
    "    EASE(name='EASE lamb=800, posB=True', lamb=800, posB=True, seed=SEED),\n",
    "    EASE(name='EASE lamb=500, posB=False', lamb=500, posB=False, seed=SEED),\n",
    "    EASE(name='EASE lamb=300, posB=False', lamb=300, posB=False, seed=SEED),\n",
    "    EASE(name='EASE lamb=800, posB=False', lamb=800, posB=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                          |    MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "EASE lamb=500, posB=True  | 0.0406 |  0.0460 |       0.0126 |    0.0771 |   48.7037 |  40.0161\n",
      "EASE lamb=300, posB=True  | 0.0404 |  0.0456 |       0.0125 |    0.0767 |   46.7271 |  38.7585\n",
      "EASE lamb=800, posB=True  | 0.0408 |  0.0461 |       0.0126 |    0.0771 |   48.3324 |  40.2958\n",
      "EASE lamb=500, posB=False | 0.0394 |  0.0453 |       0.0123 |    0.0759 |   48.9436 |  44.1733\n",
      "EASE lamb=300, posB=False | 0.0392 |  0.0450 |       0.0122 |    0.0756 |   48.5401 |  44.9813\n",
      "EASE lamb=800, posB=False | 0.0396 |  0.0455 |       0.0124 |    0.0761 |   48.5227 |  43.8767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ease_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. HPF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_models = [\n",
    "    HPF(name='HPF k=5, hierarchical=True', k=5, hierarchical=True, seed=SEED),\n",
    "    HPF(name='HPF k=10, hierarchical=True', k=10, hierarchical=True, seed=SEED),\n",
    "    HPF(name='HPF k=15, hierarchical=True', k=15, hierarchical=True, seed=SEED),\n",
    "    HPF(name='HPF k=5, hierarchical=False', k=5, hierarchical=False, seed=SEED),\n",
    "    HPF(name='HPF k=10, hierarchical=False', k=10, hierarchical=False, seed=SEED),\n",
    "    HPF(name='HPF k=15, hierarchical=False', k=15, hierarchical=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning...\n",
      "Learning completed!\n",
      "Learning...\n",
      "Learning completed!\n",
      "Learning...\n",
      "Learning completed!\n",
      "Learning...\n",
      "Learning completed!\n",
      "Learning...\n",
      "Learning completed!\n",
      "Learning...\n",
      "Learning completed!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                             |    MAP | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "---------------------------- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "HPF k=5, hierarchical=True   | 0.0193 |  0.0205 |       0.0060 |    0.0369 |   52.4575 |  43.8802\n",
      "HPF k=10, hierarchical=True  | 0.0175 |  0.0191 |       0.0057 |    0.0345 |  103.9741 |  44.7900\n",
      "HPF k=15, hierarchical=True  | 0.0157 |  0.0167 |       0.0051 |    0.0300 |  160.5110 |  45.2499\n",
      "HPF k=5, hierarchical=False  | 0.0198 |  0.0214 |       0.0065 |    0.0389 |   51.9678 |  43.6735\n",
      "HPF k=10, hierarchical=False | 0.0187 |  0.0195 |       0.0056 |    0.0336 |   99.7340 |  43.7865\n",
      "HPF k=15, hierarchical=False | 0.0162 |  0.0164 |       0.0049 |    0.0279 |  157.7568 |  43.2988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=hpf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. IBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibpr_models = [\n",
    "    IBPR(name='IBPR k=20, lamda=0.001', k=20, lamda=0.001),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ibpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## too long to train\n",
    "472m of training time - still not converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. SANSA hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sansa_models = [\n",
    "    # SANSA(name='SANSA l2=1, factorizer_class=CHOLMOD', l2=1, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    # SANSA(name='SANSA l2=10, factorizer_class=CHOLMOD', l2=10, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    # SANSA(name='SANSA l2=500, factorizer_class=CHOLMOD', l2=500, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=1, factorizer_class=ICF', l2=1, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=10, factorizer_class=ICF', l2=10, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=500, factorizer_class=ICF', l2=500, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 1*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0000e+00. Continuing with L2=1.0010e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0010e+00. Continuing with L2=1.0020e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0020e+00. Continuing with L2=1.0040e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0040e+00. Continuing with L2=1.0080e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0080e+00. Continuing with L2=1.0160e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0160e+00. Continuing with L2=1.0320e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0320e+00. Continuing with L2=1.0640e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0640e+00. Continuing with L2=1.1280e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.1280e+00. Continuing with L2=1.2560e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.2560e+00. Continuing with L2=1.5120e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.5120e+00. Continuing with L2=2.0240e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=2.0240e+00. Continuing with L2=3.0480e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=3.0480e+00. Continuing with L2=5.0960e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=5.0960e+00. Continuing with L2=9.1920e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=9.1920e+00. Continuing with L2=1.7384e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.7384e+01. Continuing with L2=3.3768e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=3.3768e+01. Continuing with L2=6.6536e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=6.6536e+01. Continuing with L2=1.3207e+02.\n",
      "                \n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.010785768739879131, relative Frobenius norm squared: 1.737253683131712e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00875471904873848, relative Frobenius norm squared: 1.196500107880638e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00864958856254816, relative Frobenius norm squared: 4.947395026988488e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0031652264297008514, relative Frobenius norm squared: 2.601983162264787e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.002836677012965083, relative Frobenius norm squared: 2.00701393282543e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0024244708474725485, relative Frobenius norm squared: 1.4765593192578308e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0023744963109493256, relative Frobenius norm squared: 1.0757798207805536e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0021283195819705725, relative Frobenius norm squared: 6.483971581872083e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0011736646993085742, relative Frobenius norm squared: 3.5750975513337835e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0011534752557054162, relative Frobenius norm squared: 2.3141544236437994e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 0.0006059702136553824, relative Frobenius norm squared: 1.4212617749365108e-09\n",
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 10*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0000e+01. Continuing with L2=1.0001e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0001e+01. Continuing with L2=1.0002e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0002e+01. Continuing with L2=1.0004e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0004e+01. Continuing with L2=1.0008e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0008e+01. Continuing with L2=1.0016e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0016e+01. Continuing with L2=1.0032e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0032e+01. Continuing with L2=1.0064e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0064e+01. Continuing with L2=1.0128e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0128e+01. Continuing with L2=1.0256e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0256e+01. Continuing with L2=1.0512e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0512e+01. Continuing with L2=1.1024e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.1024e+01. Continuing with L2=1.2048e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.2048e+01. Continuing with L2=1.4096e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.4096e+01. Continuing with L2=1.8192e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.8192e+01. Continuing with L2=2.6384e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=2.6384e+01. Continuing with L2=4.2768e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=4.2768e+01. Continuing with L2=7.5536e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=7.5536e+01. Continuing with L2=1.4107e+02.\n",
      "                \n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.011554921045899391, relative Frobenius norm squared: 1.1667015087368782e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.006918673403561115, relative Frobenius norm squared: 7.337567353715713e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00683331536129117, relative Frobenius norm squared: 2.622283901132505e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00229967525228858, relative Frobenius norm squared: 1.22548140524259e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0019128586864098907, relative Frobenius norm squared: 9.673561507383965e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0019128586864098907, relative Frobenius norm squared: 7.36337879558846e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0017101822886615992, relative Frobenius norm squared: 4.89818630100558e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.001582152908667922, relative Frobenius norm squared: 2.8941544716332146e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0008230491075664759, relative Frobenius norm squared: 1.5233871941688903e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0007286383188329637, relative Frobenius norm squared: 9.993524896501071e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 0.0005741298082284629, relative Frobenius norm squared: 6.192290569195791e-10\n",
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 500*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004914141609333456, relative Frobenius norm squared: 4.086995464280818e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00044483866076916456, relative Frobenius norm squared: 1.8023797732080737e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00015953627007547766, relative Frobenius norm squared: 2.8534128185264684e-11\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0001239056437043473, relative Frobenius norm squared: 1.4247552790336293e-11\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 5.9353536926209927e-05, relative Frobenius norm squared: 1.8727985742067466e-12\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 3.390949495951645e-05, relative Frobenius norm squared: 6.13674367398731e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 9.245634828403126e-06, relative Frobenius norm squared: 1.8585217457893488e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 6.669334652542602e-06, relative Frobenius norm squared: 1.5029537130898524e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 4.4475636968854815e-06, relative Frobenius norm squared: 1.2890536348845322e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 4.0929608076112345e-06, relative Frobenius norm squared: 1.142684850821002e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                   |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "---------------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "SANSA l2=1, factorizer_class=ICF   | 0.0191 | 0.0300 |  0.0225 |       0.0066 |    0.0375 |   16.8820 |  36.4241\n",
      "SANSA l2=10, factorizer_class=ICF  | 0.0191 | 0.0300 |  0.0225 |       0.0066 |    0.0375 |   16.0139 |  35.5143\n",
      "SANSA l2=500, factorizer_class=ICF | 0.0191 | 0.0300 |  0.0226 |       0.0066 |    0.0376 |    6.6424 |  33.9904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=sansa_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. VAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaecf_models = [\n",
    "    VAECF(name='VAECF k=5, likelihood=mult', k=5, likelihood=\"mult\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=5, likelihood=gaus', k=5, likelihood=\"gaus\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=10, likelihood=mult', k=10, likelihood=\"mult\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=10, likelihood=gaus', k=10, likelihood=\"gaus\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                            |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) |  Test (s)\n",
      "--------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + ---------\n",
      "VAECF k=5, likelihood=mult  | 0.0298 | 0.0410 |  0.0316 |       0.0100 |    0.0614 |  297.3855 |   58.0917\n",
      "VAECF k=5, likelihood=gaus  | 0.0268 | 0.0354 |  0.0263 |       0.0079 |    0.0511 | 3190.6507 | 1090.2030\n",
      "VAECF k=10, likelihood=mult | 0.0290 | 0.0396 |  0.0300 |       0.0095 |    0.0582 | 2086.4787 |   57.7111\n",
      "VAECF k=10, likelihood=gaus | 0.0269 | 0.0356 |  0.0264 |       0.0079 |    0.0511 | 1260.1899 |   56.8296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=vaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. NeuMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_models = [\n",
    "    NeuMF(verbose=False, backend=\"pytorch\", seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "----- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "NeuMF | 0.0263 | 0.0381 |  0.0275 |       0.0087 |    0.0491 |  276.8628 | 124.8260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=neumf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
