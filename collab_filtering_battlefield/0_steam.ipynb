{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(16)\n",
    "torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import MF, PMF, BPR, SANSA, BiVAECF, LightGCN, RecVAE, EASE, NGCF, VAECF, IBPR, NeuMF, HPF, GCMC, WBPR\n",
    "from cornac.metrics import Precision, Recall, NDCG, MAP, MRR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def stratified_ranking_split(\n",
    "    df: pd.DataFrame,\n",
    "    entity_field: str,\n",
    "    test_size: float = 0.1,\n",
    "    random_state: Optional[int] = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a ranking-based dataset into training and test sets while preserving the entity distribution.\n",
    "\n",
    "    This function is useful for ranking models (e.g., next-best-offer, personalized recommendations) where each\n",
    "    entity (e.g., user) has multiple interactions with different items, and stratification ensures that\n",
    "    different user interaction levels are maintained in both splits.\n",
    "\n",
    "    Parameters:\n",
    "        df: The ranking dataset, where each row represents an interaction between an entity (e.g., user)\n",
    "            and an item (e.g., game, offer).\n",
    "        entity_field: The column representing the entity to be stratified.\n",
    "        test_size: Fraction of unique entities to allocate to the test set.\n",
    "        random_state: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DataFrames containing training and test data.\n",
    "\n",
    "    Example:\n",
    "        >>> train_validation_df, test_df = stratified_ranking_split(df, entity_field='user_id', test_size=0.1)\n",
    "        >>> train_df, validation_df = stratified_ranking_split(\n",
    "        ...     train_validation_df, entity_field='user_id', test_size=0.1\n",
    "        ... )\n",
    "        >>> print(train_df.shape, validation_df.shape, test_df.shape)\n",
    "    \"\"\"\n",
    "    entity_interaction_counts = df[entity_field].value_counts()\n",
    "\n",
    "    interaction_frequencies = entity_interaction_counts.value_counts()\n",
    "    stratifiable_interaction_counts = interaction_frequencies[interaction_frequencies >= 2].index\n",
    "\n",
    "    stratifiable_entities = entity_interaction_counts[\n",
    "        entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "    non_stratifiable_entities = entity_interaction_counts[\n",
    "        ~entity_interaction_counts.isin(stratifiable_interaction_counts)\n",
    "    ].index\n",
    "\n",
    "    train_strat, test_strat = (\n",
    "        train_test_split(\n",
    "            stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            stratify=entity_interaction_counts[stratifiable_entities],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        if len(stratifiable_entities) > 1\n",
    "        else (stratifiable_entities, [])\n",
    "    )\n",
    "\n",
    "    if len(non_stratifiable_entities) > 1:\n",
    "        train_non_strat, test_non_strat = train_test_split(\n",
    "            non_stratifiable_entities,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        train_non_strat = non_stratifiable_entities\n",
    "        test_non_strat = []\n",
    "\n",
    "    train_users = np.concatenate([train_strat, train_non_strat])\n",
    "    test_users = np.concatenate([test_strat, test_non_strat])\n",
    "\n",
    "    return df[df[entity_field].isin(train_users)], df[df[entity_field].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "\n",
    "metrics = [Precision(k=10), Recall(k=10), NDCG(k=10), MAP(), MRR()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_dataset = (\n",
    "    pd.read_csv(\n",
    "        \"/Users/a-shyraliev/phd/rec-sys-research/collab_filtering_battlefield/steam_recommendations.csv\",\n",
    "        usecols=['user_id', 'app_id', 'hours'],\n",
    "    )\n",
    "    .loc[:, ['user_id', 'app_id', 'hours']]\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13781059, 37610)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_dataset['user_id'].nunique(), steam_dataset['app_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, steam_dataset_sample_str = stratified_ranking_split(\n",
    "    steam_dataset,\n",
    "    entity_field='user_id',\n",
    "    test_size=0.01,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "del steam_dataset, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<121521x14807 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 325828 stored elements in Compressed Sparse Row format>,\n",
       " <121521x14807 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 62707 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RatioSplit(data=steam_dataset_sample_str.values, test_size=0.2, rating_threshold=0.0, seed=SEED)\n",
    "rs.train_set.csr_matrix, rs.test_set.csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_models = [\n",
    "    MF(name='MF k=10, lambda_reg=0.02', k=10, max_iter=200, lambda_reg=0.02, use_bias=True, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                         | MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------ + --- + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "MF k=10, lambda_reg=0.02 | nan | 0.0005 |  0.0001 |       0.0000 |    0.0003 |    0.9874 |  23.3163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=mf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_models = [\n",
    "    PMF(name='PMF k=5, lambda_reg=0.001', k=5, max_iter=200, lambda_reg=0.001, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                          |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "PMF k=5, lambda_reg=0.001 | 0.0019 | 0.0024 |  0.0019 |       0.0005 |    0.0039 |    5.6411 |  59.3444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=pmf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_models = [\n",
    "    BPR(name='BPR k=50, lambda_reg=0.01', k=50, max_iter=200, lambda_reg=0.01, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                          |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BPR k=50, lambda_reg=0.01 | 0.0310 | 0.0425 |  0.0318 |       0.0094 |    0.0578 |    7.3132 |  61.8743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BiVAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivaecf_models = [\n",
    "    BiVAECF(name='BiVAECF k=10, encoder_structure=[20]', k=10, encoder_structure=[20], n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                     |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------------------ + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "BiVAECF k=10, encoder_structure=[20] | 0.0167 | 0.0223 |  0.0151 |       0.0044 |    0.0279 |  403.8871 |  52.1578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=bivaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RecVAE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recvae_models = [\n",
    "    RecVAE(name='RecVAE hidden_dim=600, latent_dim=200', hidden_dim=600, latent_dim=200, n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                      |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "RecVAE hidden_dim=600, latent_dim=200 | 0.0304 | 0.0463 |  0.0339 |       0.0107 |    0.0585 | 4152.2937 | 118.4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=recvae_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EASE hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ease_models = [\n",
    "    EASE(name='EASE lamb=800, posB=True', lamb=800, posB=True, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                         |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "------------------------ + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "EASE lamb=800, posB=True | 0.0408 | 0.0577 |  0.0461 |       0.0126 |    0.0771 |   31.2813 |  44.3687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ease_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. HPF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf_models = [\n",
    "    HPF(name='HPF k=5, hierarchical=False', k=5, hierarchical=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning...\n",
      "Learning completed!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                            |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "--------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "HPF k=5, hierarchical=False | 0.0198 | 0.0286 |  0.0214 |       0.0065 |    0.0389 |   53.2573 |  61.7736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=hpf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. IBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibpr_models = [\n",
    "    IBPR(name='IBPR k=20, lamda=0.001', k=20, lamda=0.001),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ibpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## too long to train\n",
    "472m of training time - still not converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. SANSA hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sansa_models = [\n",
    "    # SANSA(name='SANSA l2=1, factorizer_class=CHOLMOD', l2=1, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    # SANSA(name='SANSA l2=10, factorizer_class=CHOLMOD', l2=10, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    # SANSA(name='SANSA l2=500, factorizer_class=CHOLMOD', l2=500, factorizer_class=\"CHOLMOD\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=1, factorizer_class=ICF', l2=1, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=10, factorizer_class=ICF', l2=10, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "    SANSA(name='SANSA l2=500, factorizer_class=ICF', l2=500, factorizer_class=\"ICF\", verbose=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 1*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0000e+00. Continuing with L2=1.0010e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0010e+00. Continuing with L2=1.0020e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0020e+00. Continuing with L2=1.0040e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0040e+00. Continuing with L2=1.0080e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0080e+00. Continuing with L2=1.0160e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0160e+00. Continuing with L2=1.0320e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0320e+00. Continuing with L2=1.0640e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0640e+00. Continuing with L2=1.1280e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.1280e+00. Continuing with L2=1.2560e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.2560e+00. Continuing with L2=1.5120e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.5120e+00. Continuing with L2=2.0240e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=2.0240e+00. Continuing with L2=3.0480e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=3.0480e+00. Continuing with L2=5.0960e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=5.0960e+00. Continuing with L2=9.1920e+00.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=9.1920e+00. Continuing with L2=1.7384e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.7384e+01. Continuing with L2=3.3768e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=3.3768e+01. Continuing with L2=6.6536e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=6.6536e+01. Continuing with L2=1.3207e+02.\n",
      "                \n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.04819279909133911, relative Frobenius norm squared: 3.5341001876076916e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.010785768739879131, relative Frobenius norm squared: 1.737253683131712e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00875471904873848, relative Frobenius norm squared: 1.196500107880638e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00864958856254816, relative Frobenius norm squared: 4.947395026988488e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0031652264297008514, relative Frobenius norm squared: 2.601983162264787e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.002836677012965083, relative Frobenius norm squared: 2.00701393282543e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0024244708474725485, relative Frobenius norm squared: 1.4765593192578308e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0023744963109493256, relative Frobenius norm squared: 1.0757798207805536e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0021283195819705725, relative Frobenius norm squared: 6.483971581872083e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0011736646993085742, relative Frobenius norm squared: 3.5750975513337835e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0011534752557054162, relative Frobenius norm squared: 2.3141544236437994e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 0.0006059702136553824, relative Frobenius norm squared: 1.4212617749365108e-09\n",
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 10*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0000e+01. Continuing with L2=1.0001e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0001e+01. Continuing with L2=1.0002e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0002e+01. Continuing with L2=1.0004e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0004e+01. Continuing with L2=1.0008e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0008e+01. Continuing with L2=1.0016e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0016e+01. Continuing with L2=1.0032e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0032e+01. Continuing with L2=1.0064e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0064e+01. Continuing with L2=1.0128e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0128e+01. Continuing with L2=1.0256e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0256e+01. Continuing with L2=1.0512e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.0512e+01. Continuing with L2=1.1024e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.1024e+01. Continuing with L2=1.2048e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.2048e+01. Continuing with L2=1.4096e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.4096e+01. Continuing with L2=1.8192e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=1.8192e+01. Continuing with L2=2.6384e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=2.6384e+01. Continuing with L2=4.2768e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=4.2768e+01. Continuing with L2=7.5536e+01.\n",
      "                \n",
      "INFO:sansa.core._ops._factor_ops:\n",
      "                Incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A \n",
      "                with L2=7.5536e+01. Continuing with L2=1.4107e+02.\n",
      "                \n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.03505629673600197, relative Frobenius norm squared: 2.16578791878419e-06\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.011554921045899391, relative Frobenius norm squared: 1.1667015087368782e-07\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.006918673403561115, relative Frobenius norm squared: 7.337567353715713e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00683331536129117, relative Frobenius norm squared: 2.622283901132505e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00229967525228858, relative Frobenius norm squared: 1.22548140524259e-08\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0019128586864098907, relative Frobenius norm squared: 9.673561507383965e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0019128586864098907, relative Frobenius norm squared: 7.36337879558846e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0017101822886615992, relative Frobenius norm squared: 4.89818630100558e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.001582152908667922, relative Frobenius norm squared: 2.8941544716332146e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0008230491075664759, relative Frobenius norm squared: 1.5233871941688903e-09\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0007286383188329637, relative Frobenius norm squared: 9.993524896501071e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 0.0005741298082284629, relative Frobenius norm squared: 6.192290569195791e-10\n",
      "INFO:sansa.core.factorizers:Computing incomplete Cholesky decomposition of X^TX + 500*I...\n",
      "INFO:sansa.core.factorizers:Finding a fill-in reducing ordering (method = colamd)...\n",
      "INFO:sansa.core.factorizers:Computing X^TX...\n",
      "INFO:sansa.core.factorizers:\n",
      "                X^TX info:\n",
      "                    shape = (14807, 14807) \n",
      "                    nnz = 2905784 \n",
      "                    density = 1.325346% \n",
      "                    size = 23.3 MB\n",
      "                \n",
      "INFO:sansa.core.factorizers:Sorting indices of A...\n",
      "INFO:sansa.core.factorizers:Casting indptr of A to int64...\n",
      "INFO:sansa.core.factorizers:Casting indices of A to int64...\n",
      "INFO:sansa.core.factorizers:Computing approximate Cholesky decomposition (method = ICF)...\n",
      "INFO:sansa.core.factorizers:Scaling columns and creating diagonal matrix D (LL^T -> L'DL'^T)...\n",
      "INFO:sansa.core.inverters:Calculating initial guess using 1 step of Schultz method...\n",
      "INFO:sansa.core.inverters:Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR scan 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004984451807104051, relative Frobenius norm squared: 6.540675223654091e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 1...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0004914141609333456, relative Frobenius norm squared: 4.086995464280818e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 2...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00044483866076916456, relative Frobenius norm squared: 1.8023797732080737e-10\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 3...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.00015953627007547766, relative Frobenius norm squared: 2.8534128185264684e-11\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 4...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 0.0001239056437043473, relative Frobenius norm squared: 1.4247552790336293e-11\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 5...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 5.9353536926209927e-05, relative Frobenius norm squared: 1.8727985742067466e-12\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 6...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 3.390949495951645e-05, relative Frobenius norm squared: 6.13674367398731e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 7...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 9.245634828403126e-06, relative Frobenius norm squared: 1.8585217457893488e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 8...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 6.669334652542602e-06, relative Frobenius norm squared: 1.5029537130898524e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 9...\n",
      "INFO:sansa.core._ops._inverse_ops:Current maximum residual: 4.4475636968854815e-06, relative Frobenius norm squared: 1.2890536348845322e-13\n",
      "INFO:sansa.core._ops._inverse_ops:Performing UMR finetune step 10...\n",
      "INFO:sansa.core.inverters:Current maximum residual: 4.0929608076112345e-06, relative Frobenius norm squared: 1.142684850821002e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                                   |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "---------------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "SANSA l2=1, factorizer_class=ICF   | 0.0191 | 0.0300 |  0.0225 |       0.0066 |    0.0375 |   16.8820 |  36.4241\n",
      "SANSA l2=10, factorizer_class=ICF  | 0.0191 | 0.0300 |  0.0225 |       0.0066 |    0.0375 |   16.0139 |  35.5143\n",
      "SANSA l2=500, factorizer_class=ICF | 0.0191 | 0.0300 |  0.0226 |       0.0066 |    0.0376 |    6.6424 |  33.9904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=sansa_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. VAECF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaecf_models = [\n",
    "    VAECF(name='VAECF k=5, likelihood=mult', k=5, likelihood=\"mult\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=5, likelihood=gaus', k=5, likelihood=\"gaus\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=10, likelihood=mult', k=10, likelihood=\"mult\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "    VAECF(name='VAECF k=10, likelihood=gaus', k=10, likelihood=\"gaus\", n_epochs=10, use_gpu=False, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                            |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) |  Test (s)\n",
      "--------------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + ---------\n",
      "VAECF k=5, likelihood=mult  | 0.0298 | 0.0410 |  0.0316 |       0.0100 |    0.0614 |  297.3855 |   58.0917\n",
      "VAECF k=5, likelihood=gaus  | 0.0268 | 0.0354 |  0.0263 |       0.0079 |    0.0511 | 3190.6507 | 1090.2030\n",
      "VAECF k=10, likelihood=mult | 0.0290 | 0.0396 |  0.0300 |       0.0095 |    0.0582 | 2086.4787 |   57.7111\n",
      "VAECF k=10, likelihood=gaus | 0.0269 | 0.0356 |  0.0264 |       0.0079 |    0.0511 | 1260.1899 |   56.8296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=vaecf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. NeuMF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_models = [\n",
    "    NeuMF(name='NeuMF num_factors=8', num_factors=8, verbose=False, backend=\"pytorch\", seed=SEED),\n",
    "    NeuMF(name='NeuMF num_factors=20', num_factors=20, verbose=False, backend=\"pytorch\", seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "                     |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "-------------------- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "NeuMF num_factors=8  | 0.0270 | 0.0392 |  0.0282 |       0.0089 |    0.0498 |  303.9657 | 121.3155\n",
      "NeuMF num_factors=20 | 0.0268 | 0.0388 |  0.0282 |       0.0089 |    0.0510 |  302.2828 | 122.5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=neumf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. LightGCN hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn_models = [\n",
    "    LightGCN(verbose=False, num_epochs=10, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcornac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlightgcn_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/experiment/experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 142\u001b[0m     test_result, val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mappend(test_result)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/eval_methods/base_method.py:734\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[0;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] Training started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    733\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 734\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# EVALUATION #\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/lightgcn/recom_lightgcn.py:157\u001b[0m, in \u001b[0;36mLightGCN.fit\u001b[0;34m(self, train_set, val_set)\u001b[0m\n\u001b[1;32m    155\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    156\u001b[0m accum_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_u, batch_i, batch_j \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    158\u001b[0m     train_set\u001b[38;5;241m.\u001b[39muij_iter(\n\u001b[1;32m    159\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    160\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m     ),\n\u001b[1;32m    162\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m     total\u001b[38;5;241m=\u001b[39mtrain_set\u001b[38;5;241m.\u001b[39mnum_batches(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size),\n\u001b[1;32m    164\u001b[0m     leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    165\u001b[0m     position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    166\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    167\u001b[0m ):\n\u001b[1;32m    168\u001b[0m     u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m    169\u001b[0m         graph, batch_u, batch_i, batch_j\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     batch_loss, batch_bpr_loss, batch_reg_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_fn(\n\u001b[1;32m    173\u001b[0m         u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings\n\u001b[1;32m    174\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tqdm/std.py:1169\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/data/dataset.py:523\u001b[0m, in \u001b[0;36mDataset.uij_iter\u001b[0;34m(self, batch_size, shuffle, neg_sampling)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (user, pos_rating) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(batch_users, batch_pos_ratings)):\n\u001b[1;32m    522\u001b[0m     neg_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice(neg_population)\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdok_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_item\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m pos_rating:\n\u001b[1;32m    524\u001b[0m         neg_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice(neg_population)\n\u001b[1;32m    525\u001b[0m     batch_neg_items[i] \u001b[38;5;241m=\u001b[39m neg_item\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/sparse/_dok.py:145\u001b[0m, in \u001b[0;36m_dok_base.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    148\u001b[0m         key \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/sparse/_index.py:52\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 52\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/sparse/_index.py:162\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    160\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[43m_unpack_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_bool_idx\u001b[39m(\n\u001b[1;32m    166\u001b[0m     idx: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_],\n\u001b[1;32m    167\u001b[0m     axis_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    168\u001b[0m     axis_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mint_]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/sparse/_index.py:323\u001b[0m, in \u001b[0;36m_unpack_index\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# Next, check for validity and transform the index as needed.\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(row) \u001b[38;5;129;01mor\u001b[39;00m issparse(col):\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# Supporting sparse boolean indexing with both row and col does\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# not work because spmatrix.ndim is always 2.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndexing with sparse matrices is not supported \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexcept boolean indexing where matrix and index \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mare equal shapes.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=lightgcn_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1125 mins of training - not finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. NGCF hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngcf_models = [\n",
    "    NGCF(verbose=False, num_epochs=10, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=ngcf_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's slower than LightGCN -> won't finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. GCMC hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcmc_models = [\n",
    "    GCMC(verbose=False, max_iter=100, seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a-shyraliev/Library/Python/3.9/lib/python/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcornac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcmc_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/experiment/experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 142\u001b[0m     test_result, val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mappend(test_result)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/eval_methods/base_method.py:734\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[0;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] Training started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    733\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 734\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# EVALUATION #\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/gcmc/recom_gcmc.py:163\u001b[0m, in \u001b[0;36mGCMC.fit\u001b[0;34m(self, train_set, val_set)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgcmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrating_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(train_set\u001b[38;5;241m.\u001b[39muir_tuple[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrating_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_users\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgcn_agg_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn_agg_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgcn_out_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn_out_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgcn_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgcn_agg_accum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn_agg_accum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_r_num_basis_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_r_num_basis_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m    179\u001b[0m         train_set,\n\u001b[1;32m    180\u001b[0m         val_set,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m         train_lr_decay_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_lr_decay_factor,\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/gcmc/gcmc.py:49\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, rating_values, total_users, total_items, activation_func, gcn_agg_units, gcn_out_units, gcn_dropout, gcn_agg_accum, share_param, gen_r_num_basis_func, verbose, seed)\u001b[0m\n\u001b[1;32m     46\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Build Net\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_users\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_agg_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_out_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_agg_accum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_r_num_basis_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshare_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/gcmc/nn_modules.py:33\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[0;34m(self, activation_func, rating_values, n_users, n_items, gcn_agg_units, gcn_out_units, gcn_dropout, gcn_agg_accum, gen_r_num_basis_func, share_param, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28msuper\u001b[39m(NeuralNetwork, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act \u001b[38;5;241m=\u001b[39m get_activation(activation_func)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mGCMCLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_users\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_agg_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_out_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcn_agg_accum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43magg_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_act\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshare_user_item_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m BiDecoder(\n\u001b[1;32m     46\u001b[0m     in_units\u001b[38;5;241m=\u001b[39mgcn_out_units,\n\u001b[1;32m     47\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(rating_values),\n\u001b[1;32m     48\u001b[0m     num_basis\u001b[38;5;241m=\u001b[39mgen_r_num_basis_func,\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cornac/models/gcmc/nn_modules.py:232\u001b[0m, in \u001b[0;36mGCMCLayer.__init__\u001b[0;34m(self, rating_vals, user_in_units, item_in_units, msg_units, out_units, dropout_rate, agg, agg_act, out_act, share_user_item_param, device)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mifc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(msg_units, out_units)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# divide the original msg unit size by number of ratings to keep\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# the dimensionality\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m msg_units \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(rating_vals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    233\u001b[0m     msg_units \u001b[38;5;241m=\u001b[39m msg_units \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(rating_vals)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(dropout_rate)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=gcmc_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. WBPR hyperparams optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbpr_models = [\n",
    "    WBPR(seed=SEED),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "     |    MAP |    MRR | NDCG@10 | Precision@10 | Recall@10 | Train (s) | Test (s)\n",
      "---- + ------ + ------ + ------- + ------------ + --------- + --------- + --------\n",
      "WBPR | 0.0051 | 0.0080 |  0.0030 |       0.0009 |    0.0048 |    1.9612 |  55.3430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cornac.Experiment(\n",
    "    eval_method=rs,\n",
    "    models=wbpr_models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None,\n",
    ").run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
